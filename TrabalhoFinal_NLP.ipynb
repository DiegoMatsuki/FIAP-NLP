{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TemplateTrabalhoFinal_NLP.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "qO7dIjulAVsi",
        "21bsoQoOAVsi",
        "3bWn0x89Ep7y",
        "Fhtt8tIeAVsi",
        "07WGfYX-AVsj",
        "zwaiKz5yAVsk",
        "D03oTkcMAVsk",
        "JVg8yT6lFBqm",
        "gKO0kmI_FBqo",
        "anCEXxdZFBqp",
        "nbXqn2LYFBqp",
        "sWkBlMS5FBqq",
        "3FNfgMUzFCjT",
        "wnlUT-uYn-2F",
        "c7nnIyU7g_vT",
        "f4eiNR3eMOGH",
        "gSuUldn2MPCF",
        "HRyIcxvEMPCF",
        "fc6nXbUmMPCG",
        "E2p35LnFMPCG",
        "fpe8kpA6MPCH",
        "cytiQwJxiHgj",
        "CglYqDOFiHgq",
        "jNLJ18BEiHgq",
        "loj_Qol5iHgs",
        "6z5w5HvViHgt",
        "cBeDtIfWiHgt",
        "LegkemmJiHgu",
        "k1N9YBQxiHgz",
        "jq6bQ0evvCHT"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xw6WhaNo4k3"
      },
      "source": [
        "### Criar um classificador de sentimento aplicando técnicas de PLN\n",
        "---\n",
        "\n",
        "Utilizando o dataset de revisões de filmes em português [1], criar um classificador de sentimentos que consiga um score na métrica F1 Score superior a 70%.\n",
        "\n",
        "Devem utilizar uma amostra de 20% e randon_state igual a 42 para testar as implementações e mensurar a métrica F1 Score (usar o parâmetro average = 'weighted') o restante dos dados devem ser utilizados para o treinamento (80%).\n",
        "\n",
        "Fique a vontade para testar os métodos de pré-processamento, abordagens, algoritmos e bibliotecas, mas explique e justifique suas decisões.\n",
        "O trabalho poderá ser feito em grupo de até 4 pessoas (mesmo grupo do Startup One).\n",
        "Separar a implementação do seu modelo campeão e a parte de validação do resultado conforme template disponibilizado, a ideia é simular a implementação de um modelo produtivo.\n",
        "\n",
        "Composição da nota:\n",
        "- 50% - Demonstrações das aplicações das técnicas de PLN (regras, pré-processamentos, tratamnentos, varierade de modelos aplicados, etc.)\n",
        "- 50% - Baseado na performance obtida com o dataset de teste do seu modelo e na validação que o professor processar (Métrica F1 Score).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzhQpodBpRpX"
      },
      "source": [
        "[1] - https://dados-ml-pln.s3-sa-east-1.amazonaws.com/reviews-pt-br.csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMBI8SQtps1n"
      },
      "source": [
        "#CARREGANDO O DATA FRAME\n",
        "import pandas as pd\n",
        "# df_full = pd.read_csv('https://dados-ml-pln.s3-sa-east-1.amazonaws.com/reviews-pt-br.csv', encoding='utf-8')\n",
        "df_full = pd.read_csv('bases/reviews-pt-br.csv', encoding='utf-8')\n",
        "\n",
        "df = df_full.sample(n=1000, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s__lBzDQwrcG",
        "outputId": "b81aeb10-8a21-42ca-cf4b-fbf7df92c725"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 1000 entries, 15538 to 21350\n",
            "Data columns (total 3 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   codigo      1000 non-null   int64 \n",
            " 1   texto       1000 non-null   object\n",
            " 2   sentimento  1000 non-null   object\n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 31.2+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LbWn9VZcAVsg",
        "outputId": "b0331ed7-0129-4ace-d891-8348e61fdf55"
      },
      "source": [
        "# Separando os Data Frames entre treino e teste\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df_train, df_test = train_test_split(\n",
        "    df.copy(), \n",
        "    test_size = 0.2, \n",
        "    random_state = 42\n",
        ")\n",
        "\n",
        "print('Treino: df_train', df_train.shape)\n",
        "print('Treino: df_test', df_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Treino: df_train (800, 3)\n",
            "Treino: df_test (200, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MKPbAibAVsg",
        "outputId": "a8308fb6-0a21-4962-b2a5-3dfd2087689b"
      },
      "source": [
        "# Import e downlaod de bibliotecas utilizadas a seguir\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "from nltk.stem.rslp import RSLPStemmer\n",
        "from nltk.stem import SnowballStemmer\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('rslp')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "import spacy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]   Package rslp is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyKC9Vhkp0BK"
      },
      "source": [
        "Bom desenvolvimento!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SedbPFXVAVsh"
      },
      "source": [
        "resultado = [] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vTWgdzKAVsh"
      },
      "source": [
        "stopwords = nltk.corpus.stopwords.words('portuguese')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qO7dIjulAVsi"
      },
      "source": [
        "## Stemming"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pBWXU1mAVsi"
      },
      "source": [
        "# Criação das coluna de tokens \n",
        "df_train['tokens'] = df_train.texto.apply(word_tokenize)\n",
        "df_test['tokens'] = df_test.texto.apply(word_tokenize)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pyYIC3VAVsi"
      },
      "source": [
        "# Criação das coluna RSLP Stemmer\n",
        "rslp = RSLPStemmer()\n",
        "\n",
        "def stem_pandas(line):\n",
        "  return ' '.join([rslp.stem(token) for token in line])\n",
        "\n",
        "df_train['stemmer'] = df_train.tokens.apply(stem_pandas)\n",
        "df_test['stemmer'] = df_test.tokens.apply(stem_pandas)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-4Cjl_MAVsi"
      },
      "source": [
        "# Criação das coluna Snowball Stemmer\n",
        "snowball = SnowballStemmer(\"portuguese\")\n",
        "\n",
        "def stemsnow_pandas(line):\n",
        "  return ' '.join([snowball.stem(token) for token in line])\n",
        "\n",
        "df_train['stemmersnow'] = df_train.tokens.apply(stemsnow_pandas)\n",
        "df_test['stemmersnow'] = df_test.tokens.apply(stemsnow_pandas)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tau1L3-mk7IT"
      },
      "source": [
        "## Lemmatização"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rh1lk55Yri4N"
      },
      "source": [
        "# !pip install --upgrade spacy\n",
        "# !python -m spacy download pt_core_news_sm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZyrPYN5lL2j"
      },
      "source": [
        "nlp = spacy.load('pt_core_news_sm')\n",
        "stopwords_spacy = nlp.Defaults.stop_words\n",
        "\n",
        "def lemmatizer_spacy(line):\n",
        "  return ' '.join([token.lemma_ for token in nlp(line)])\n",
        "\n",
        "df_train['lemma'] = df_train.texto.apply(lemmatizer_spacy)\n",
        "df_test['lemma'] = df_test.texto.apply(lemmatizer_spacy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21bsoQoOAVsi"
      },
      "source": [
        "## Vetorização"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bWn0x89Ep7y"
      },
      "source": [
        "### Texto"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fhtt8tIeAVsi"
      },
      "source": [
        "#### CountVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4JVtLEKAVsj"
      },
      "source": [
        "# vetorização da base de treino\n",
        "text_count1Vect = CountVectorizer(ngram_range=(1,1))\n",
        "text_count1Vect.fit(df_train.texto)\n",
        "text_count1Vect_train = text_count1Vect.transform(df_train.texto)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1fsXYCTAVsj"
      },
      "source": [
        "# vetorização da base de treino\n",
        "text_count2Vect = CountVectorizer(ngram_range=(2,2))\n",
        "text_count2Vect.fit(df_train.texto)\n",
        "text_count2Vect_train = text_count2Vect.transform(df_train.texto)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkGLMeQtAVsj"
      },
      "source": [
        "# vetorização da base de treino\n",
        "text_count3Vect = CountVectorizer(ngram_range=(3,3))\n",
        "text_count3Vect.fit(df_train.texto)\n",
        "text_count3Vect_train = text_count3Vect.transform(df_train.texto)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07WGfYX-AVsj"
      },
      "source": [
        "#### CountVectorizer + Stopwords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOljH3pTAVsj"
      },
      "source": [
        "# vetorização da base de treino\n",
        "text_count1StopVect = CountVectorizer(ngram_range=(1,1), stop_words=stopwords)\n",
        "text_count1StopVect.fit(df_train.texto)\n",
        "text_count1StopVect_train = text_count1StopVect.transform(df_train.texto)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wrg3TGvAVsj"
      },
      "source": [
        "# vetorização da base de treino\n",
        "text_count2StopVect = CountVectorizer(ngram_range=(2,2), stop_words=stopwords)\n",
        "text_count2StopVect.fit(df_train.texto)\n",
        "text_count2StopVect_train = text_count2StopVect.transform(df_train.texto)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYnS7yDnAVsk"
      },
      "source": [
        "# vetorização da base de treino\n",
        "text_count3StopVect = CountVectorizer(ngram_range=(3,3), stop_words=stopwords)\n",
        "text_count3StopVect.fit(df_train.texto)\n",
        "text_count3StopVect_train = text_count3StopVect.transform(df_train.texto)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwaiKz5yAVsk"
      },
      "source": [
        "#### TfidfVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzyOvVwQAVsk"
      },
      "source": [
        "text_tfidf1Vect = TfidfVectorizer(ngram_range=(1,1), use_idf=True)\n",
        "text_tfidf1Vect.fit(df_train.texto)\n",
        "text_tfidf1Vect_train = text_tfidf1Vect.transform(df_train.texto)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upGS5Fl2AVsk"
      },
      "source": [
        "text_tfidf2Vect = TfidfVectorizer(ngram_range=(2,2), use_idf=True)\n",
        "text_tfidf2Vect.fit(df_train.texto)\n",
        "text_tfidf2Vect_train = text_tfidf2Vect.transform(df_train.texto)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ummv5AVrAVsk"
      },
      "source": [
        "text_tfidf3Vect = TfidfVectorizer(ngram_range=(3,3), use_idf=True)\n",
        "text_tfidf3Vect.fit(df_train.texto)\n",
        "text_tfidf3Vect_train = text_tfidf3Vect.transform(df_train.texto)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D03oTkcMAVsk"
      },
      "source": [
        "#### TfidfVectorizer + Stopwords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXrNTRnkAVsk"
      },
      "source": [
        "text_tfidf1StopVect = TfidfVectorizer(ngram_range=(1,1), use_idf=True, stop_words=stopwords)\n",
        "text_tfidf1StopVect.fit(df_train.texto)\n",
        "text_tfidf1StopVect_train = text_tfidf1StopVect.transform(df_train.texto)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-GnvsyXAVsl"
      },
      "source": [
        "text_tfidf2StopVect = TfidfVectorizer(ngram_range=(2,2), use_idf=True, stop_words=stopwords)\n",
        "text_tfidf2StopVect.fit(df_train.texto)\n",
        "text_tfidf2StopVect_train = text_tfidf2StopVect.transform(df_train.texto)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ur9vxpfMAVsl"
      },
      "source": [
        "text_tfidf3StopVect = TfidfVectorizer(ngram_range=(3,3), use_idf=True, stop_words=stopwords)\n",
        "text_tfidf3StopVect.fit(df_train.texto)\n",
        "text_tfidf3StopVect_train = text_tfidf3StopVect.transform(df_train.texto)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVg8yT6lFBqm"
      },
      "source": [
        "### RSLP Stemmer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKO0kmI_FBqo"
      },
      "source": [
        "#### CountVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTwWyKTQFBqo"
      },
      "source": [
        "# vetorização da base de treino\n",
        "rslp_count1Vect = CountVectorizer(ngram_range=(1,1))\n",
        "rslp_count1Vect.fit(df_train.stemmer)\n",
        "rslp_count1Vect_train = rslp_count1Vect.transform(df_train.stemmer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGXIxbNLFBqo"
      },
      "source": [
        "# vetorização da base de treino\n",
        "rslp_count2Vect = CountVectorizer(ngram_range=(2,2))\n",
        "rslp_count2Vect.fit(df_train.stemmer)\n",
        "rslp_count2Vect_train = rslp_count2Vect.transform(df_train.stemmer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmQTqz0lFBqp"
      },
      "source": [
        "# vetorização da base de treino\n",
        "rslp_count3Vect = CountVectorizer(ngram_range=(3,3))\n",
        "rslp_count3Vect.fit(df_train.stemmer)\n",
        "rslp_count3Vect_train = rslp_count3Vect.transform(df_train.stemmer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anCEXxdZFBqp"
      },
      "source": [
        "#### CountVectorizer + Stopwords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iv1lSfyEFBqp"
      },
      "source": [
        "# vetorização da base de treino\n",
        "rslp_count1StopVect = CountVectorizer(ngram_range=(1,1), stop_words=stopwords)\n",
        "rslp_count1StopVect.fit(df_train.stemmer)\n",
        "rslp_count1StopVect_train = rslp_count1StopVect.transform(df_train.stemmer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-EChLDhFBqp"
      },
      "source": [
        "# vetorização da base de treino\n",
        "rslp_count2StopVect = CountVectorizer(ngram_range=(2,2), stop_words=stopwords)\n",
        "rslp_count2StopVect.fit(df_train.stemmer)\n",
        "rslp_count2StopVect_train = rslp_count2StopVect.transform(df_train.stemmer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlAI5hHSFBqp"
      },
      "source": [
        "# vetorização da base de treino\n",
        "rslp_count3StopVect = CountVectorizer(ngram_range=(3,3), stop_words=stopwords)\n",
        "rslp_count3StopVect.fit(df_train.stemmer)\n",
        "rslp_count3StopVect_train = rslp_count3StopVect.transform(df_train.stemmer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbXqn2LYFBqp"
      },
      "source": [
        "#### TfidfVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6xFr94RFBqq"
      },
      "source": [
        "rslp_tfidf1Vect = TfidfVectorizer(ngram_range=(1,1), use_idf=True)\n",
        "rslp_tfidf1Vect.fit(df_train.stemmer)\n",
        "rslp_tfidf1Vect_train = rslp_tfidf1Vect.transform(df_train.stemmer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFpX9M8qFBqq"
      },
      "source": [
        "rslp_tfidf2Vect = TfidfVectorizer(ngram_range=(2,2), use_idf=True)\n",
        "rslp_tfidf2Vect.fit(df_train.stemmer)\n",
        "rslp_tfidf2Vect_train = rslp_tfidf2Vect.transform(df_train.stemmer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IP3HtVf9FBqq"
      },
      "source": [
        "rslp_tfidf3Vect = TfidfVectorizer(ngram_range=(3,3), use_idf=True)\n",
        "rslp_tfidf3Vect.fit(df_train.stemmer)\n",
        "rslp_tfidf3Vect_train = rslp_tfidf3Vect.transform(df_train.stemmer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWkBlMS5FBqq"
      },
      "source": [
        "#### TfidfVectorizer + Stopwords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCyTshN0FBqq"
      },
      "source": [
        "rslp_tfidf1StopVect = TfidfVectorizer(ngram_range=(1,1), use_idf=True, stop_words=stopwords)\n",
        "rslp_tfidf1StopVect.fit(df_train.stemmer)\n",
        "rslp_tfidf1StopVect_train = rslp_tfidf1StopVect.transform(df_train.stemmer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OeD_CD2hFBqq"
      },
      "source": [
        "rslp_tfidf2StopVect = TfidfVectorizer(ngram_range=(2,2), use_idf=True, stop_words=stopwords)\n",
        "rslp_tfidf2StopVect.fit(df_train.stemmer)\n",
        "rslp_tfidf2StopVect_train = rslp_tfidf2StopVect.transform(df_train.stemmer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCzgmkunFBqq"
      },
      "source": [
        "rslp_tfidf3StopVect = TfidfVectorizer(ngram_range=(3,3), use_idf=True, stop_words=stopwords)\n",
        "rslp_tfidf3StopVect.fit(df_train.stemmer)\n",
        "rslp_tfidf3StopVect_train = rslp_tfidf3StopVect.transform(df_train.stemmer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FNfgMUzFCjT"
      },
      "source": [
        "### Snowball Stemmer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCwg8GXtFCjU"
      },
      "source": [
        "#### CountVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pz4KwgC8FCjU"
      },
      "source": [
        "# vetorização da base de treino\n",
        "snow_count1Vect = CountVectorizer(ngram_range=(1,1))\n",
        "snow_count1Vect.fit(df_train.stemmersnow)\n",
        "snow_count1Vect_train = snow_count1Vect.transform(df_train.stemmersnow)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyfJ4v_WFCjU"
      },
      "source": [
        "# vetorização da base de treino\n",
        "snow_count2Vect = CountVectorizer(ngram_range=(2,2))\n",
        "snow_count2Vect.fit(df_train.stemmersnow)\n",
        "snow_count2Vect_train = snow_count2Vect.transform(df_train.stemmersnow)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJTCBxa6FCjU"
      },
      "source": [
        "# vetorização da base de treino\n",
        "snow_count3Vect = CountVectorizer(ngram_range=(3,3))\n",
        "snow_count3Vect.fit(df_train.stemmersnow)\n",
        "snow_count3Vect_train = snow_count3Vect.transform(df_train.stemmersnow)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Py45mX5sFCjU"
      },
      "source": [
        "#### CountVectorizer + Stopwords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0BPV3KYFCjU"
      },
      "source": [
        "# vetorização da base de treino\n",
        "snow_count1StopVect = CountVectorizer(ngram_range=(1,1), stop_words=stopwords)\n",
        "snow_count1StopVect.fit(df_train.stemmersnow)\n",
        "snow_count1StopVect_train = snow_count1StopVect.transform(df_train.stemmersnow)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cW-FBqjFCjU"
      },
      "source": [
        "# vetorização da base de treino\n",
        "snow_count2StopVect = CountVectorizer(ngram_range=(2,2), stop_words=stopwords)\n",
        "snow_count2StopVect.fit(df_train.stemmersnow)\n",
        "snow_count2StopVect_train = snow_count2StopVect.transform(df_train.stemmersnow)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iszjoAVWFCjU"
      },
      "source": [
        "# vetorização da base de treino\n",
        "snow_count3StopVect = CountVectorizer(ngram_range=(3,3), stop_words=stopwords)\n",
        "snow_count3StopVect.fit(df_train.stemmersnow)\n",
        "snow_count3StopVect_train = snow_count3StopVect.transform(df_train.stemmersnow)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1S5d3g0FCjV"
      },
      "source": [
        "#### TfidfVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12lcdrnEFCjV"
      },
      "source": [
        "snow_tfidf1Vect = TfidfVectorizer(ngram_range=(1,1), use_idf=True)\n",
        "snow_tfidf1Vect.fit(df_train.stemmersnow)\n",
        "snow_tfidf1Vect_train = snow_tfidf1Vect.transform(df_train.stemmersnow)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Z-igRzPFCjV"
      },
      "source": [
        "snow_tfidf2Vect = TfidfVectorizer(ngram_range=(2,2), use_idf=True)\n",
        "snow_tfidf2Vect.fit(df_train.stemmersnow)\n",
        "snow_tfidf2Vect_train = snow_tfidf2Vect.transform(df_train.stemmersnow)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxL90OA9FCjV"
      },
      "source": [
        "snow_tfidf3Vect = TfidfVectorizer(ngram_range=(3,3), use_idf=True)\n",
        "snow_tfidf3Vect.fit(df_train.stemmersnow)\n",
        "snow_tfidf3Vect_train = snow_tfidf3Vect.transform(df_train.stemmersnow)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jk5_lFSvFCjV"
      },
      "source": [
        "#### TfidfVectorizer + Stopwords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whm02YRxFCjV"
      },
      "source": [
        "snow_tfidf1StopVect = TfidfVectorizer(ngram_range=(1,1), use_idf=True, stop_words=stopwords)\n",
        "snow_tfidf1StopVect.fit(df_train.stemmersnow)\n",
        "snow_tfidf1StopVect_train = snow_tfidf1StopVect.transform(df_train.stemmersnow)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96Jt1D9dFCjV"
      },
      "source": [
        "snow_tfidf2StopVect = TfidfVectorizer(ngram_range=(2,2), use_idf=True, stop_words=stopwords)\n",
        "snow_tfidf2StopVect.fit(df_train.stemmersnow)\n",
        "snow_tfidf2StopVect_train = snow_tfidf2StopVect.transform(df_train.stemmersnow)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwQCiTowFCjV"
      },
      "source": [
        "snow_tfidf3StopVect = TfidfVectorizer(ngram_range=(3,3), use_idf=True, stop_words=stopwords)\n",
        "snow_tfidf3StopVect.fit(df_train.stemmersnow)\n",
        "snow_tfidf3StopVect_train = snow_tfidf3StopVect.transform(df_train.stemmersnow)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnlUT-uYn-2F"
      },
      "source": [
        "### Lemma"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9dlls1Yn-2M"
      },
      "source": [
        "#### CountVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEOclC-Bn-2N"
      },
      "source": [
        "# vetorização da base de treino\n",
        "lemma_count1Vect = CountVectorizer(ngram_range=(1,1))\n",
        "lemma_count1Vect.fit(df_train.lemma)\n",
        "lemma_count1Vect_train = lemma_count1Vect.transform(df_train.lemma)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4kgvXOEn-2N"
      },
      "source": [
        "# vetorização da base de treino\n",
        "lemma_count2Vect = CountVectorizer(ngram_range=(2,2))\n",
        "lemma_count2Vect.fit(df_train.lemma)\n",
        "lemma_count2Vect_train = lemma_count2Vect.transform(df_train.lemma)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcLHnuqgn-2N"
      },
      "source": [
        "# vetorização da base de treino\n",
        "lemma_count3Vect = CountVectorizer(ngram_range=(3,3))\n",
        "lemma_count3Vect.fit(df_train.lemma)\n",
        "lemma_count3Vect_train = lemma_count3Vect.transform(df_train.lemma)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOZiPG8rn-2N"
      },
      "source": [
        "#### CountVectorizer + Stopwords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4L28nYEIn-2N"
      },
      "source": [
        "# vetorização da base de treino\n",
        "lemma_count1StopVect = CountVectorizer(ngram_range=(1,1), stop_words=stopwords_spacy)\n",
        "lemma_count1StopVect.fit(df_train.lemma)\n",
        "lemma_count1StopVect_train = lemma_count1StopVect.transform(df_train.lemma)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mZlIcuXn-2O"
      },
      "source": [
        "# vetorização da base de treino\n",
        "lemma_count2StopVect = CountVectorizer(ngram_range=(2,2), stop_words=stopwords_spacy)\n",
        "lemma_count2StopVect.fit(df_train.lemma)\n",
        "lemma_count2StopVect_train = lemma_count2StopVect.transform(df_train.lemma)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oiFn7sC2n-2O"
      },
      "source": [
        "# vetorização da base de treino\n",
        "lemma_count3StopVect = CountVectorizer(ngram_range=(3,3), stop_words=stopwords_spacy)\n",
        "lemma_count3StopVect.fit(df_train.lemma)\n",
        "lemma_count3StopVect_train = lemma_count3StopVect.transform(df_train.lemma)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rf4RfTSbn-2O"
      },
      "source": [
        "#### TfidfVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxzcZhWQn-2O"
      },
      "source": [
        "lemma_tfidf1Vect = TfidfVectorizer(ngram_range=(1,1), use_idf=True)\n",
        "lemma_tfidf1Vect.fit(df_train.lemma)\n",
        "lemma_tfidf1Vect_train = lemma_tfidf1Vect.transform(df_train.lemma)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9jsl2Q2n-2O"
      },
      "source": [
        "lemma_tfidf2Vect = TfidfVectorizer(ngram_range=(2,2), use_idf=True)\n",
        "lemma_tfidf2Vect.fit(df_train.lemma)\n",
        "lemma_tfidf2Vect_train = lemma_tfidf2Vect.transform(df_train.lemma)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMMe74L8n-2O"
      },
      "source": [
        "lemma_tfidf3Vect = TfidfVectorizer(ngram_range=(3,3), use_idf=True)\n",
        "lemma_tfidf3Vect.fit(df_train.lemma)\n",
        "lemma_tfidf3Vect_train = lemma_tfidf3Vect.transform(df_train.lemma)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zZqAlfUn-2P"
      },
      "source": [
        "#### TfidfVectorizer + Stopwords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9UR4Pe9n-2P"
      },
      "source": [
        "lemma_tfidf1StopVect = TfidfVectorizer(ngram_range=(1,1), use_idf=True, stop_words=stopwords_spacy)\n",
        "lemma_tfidf1StopVect.fit(df_train.lemma)\n",
        "lemma_tfidf1StopVect_train = lemma_tfidf1StopVect.transform(df_train.lemma)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXxSyg2tn-2P"
      },
      "source": [
        "lemma_tfidf2StopVect = TfidfVectorizer(ngram_range=(2,2), use_idf=True, stop_words=stopwords_spacy)\n",
        "lemma_tfidf2StopVect.fit(df_train.lemma)\n",
        "lemma_tfidf2StopVect_train = lemma_tfidf2StopVect.transform(df_train.lemma)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6SCCZ2Wn-2P"
      },
      "source": [
        "lemma_tfidf3StopVect = TfidfVectorizer(ngram_range=(3,3), use_idf=True, stop_words=stopwords_spacy)\n",
        "lemma_tfidf3StopVect.fit(df_train.lemma)\n",
        "lemma_tfidf3StopVect_train = lemma_tfidf3StopVect.transform(df_train.lemma)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSSxX1HiAVsl"
      },
      "source": [
        "## Treinamento e escoragem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7nnIyU7g_vT"
      },
      "source": [
        "### Arvore de Decisão"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrDrtNBrLrS6"
      },
      "source": [
        "#### Texto\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6u1hkqDAVsl"
      },
      "source": [
        "##### CountVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nze8UbKhosm9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d7402cf-7780-48d7-e555-5479f2d01728"
      },
      "source": [
        "# Texto CountVectorizer Unigrama com arvore de decisão\n",
        "# treinamento do modelo árvore de decisão\n",
        "tree = DecisionTreeClassifier(random_state=42)\n",
        "tree.fit(text_count1Vect_train, df_train.sentimento)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "text_vect_test = text_count1Vect.transform(df_test.texto)\n",
        "y_prediction = tree.predict(text_vect_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "score = f1_score(y_prediction, df_test.sentimento, average='weighted')\n",
        "resultado.append(['Texto CountVectorizer Unigrama com arvore de decisão', score])\n",
        "print('Texto CountVectorizer Unigrama com arvore de decisão:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texto CountVectorizer Unigrama com arvore de decisão: 0.6751708342719831\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eeVmL7-zAVsl",
        "outputId": "c2152fe5-4729-44ba-c7c9-0f5bb96195af"
      },
      "source": [
        "# Texto CountVectorizer Bigrama com arvore de decisão\n",
        "# treinamento do modelo árvore de decisão\n",
        "tree = DecisionTreeClassifier(random_state=42)\n",
        "tree.fit(text_count2Vect_train, df_train.sentimento)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "text_vect_test = text_count2Vect.transform(df_test.texto)\n",
        "y_prediction = tree.predict(text_vect_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "score = f1_score(y_prediction, df_test.sentimento, average='weighted')\n",
        "resultado.append(['Texto CountVectorizer Bigrama com arvore de decisão', score])\n",
        "print('Texto CountVectorizer Bigrama com arvore de decisão:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texto CountVectorizer Bigrama com arvore de decisão: 0.6460427807486632\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qB7U8SydAVsm",
        "outputId": "ddc13eba-18ee-49dc-a437-642f26a48263"
      },
      "source": [
        "# Texto CountVectorizer Trigrama com arvore de decisão\n",
        "# treinamento do modelo árvore de decisão\n",
        "tree = DecisionTreeClassifier(random_state=42)\n",
        "tree.fit(text_count3Vect_train, df_train.sentimento)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "text_vect_test = text_count3Vect.transform(df_test.texto)\n",
        "y_prediction = tree.predict(text_vect_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "score = f1_score(y_prediction, df_test.sentimento, average='weighted')\n",
        "resultado.append(['Texto CountVectorizer Trigrama com arvore de decisão', score])\n",
        "print('Texto CountVectorizer Trigrama com arvore de decisão:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texto CountVectorizer Trigrama com arvore de decisão: 0.6105035526722274\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SjWrIp5HAVsm"
      },
      "source": [
        "##### CountVectorizer + Stopwords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FECO5RscAVsm",
        "outputId": "def788a3-f9f2-4d83-d4c5-b5e1c93d5ce5"
      },
      "source": [
        "# Texto CountVectorizer Unigrama e stopwords com arvore de decisão\n",
        "# treinamento do modelo árvore de decisão\n",
        "tree = DecisionTreeClassifier(random_state=42)\n",
        "tree.fit(text_count1StopVect_train, df_train.sentimento)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "text_vect_test = text_count1StopVect.transform(df_test.texto)\n",
        "y_prediction = tree.predict(text_vect_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "score = f1_score(y_prediction, df_test.sentimento, average='weighted')\n",
        "resultado.append(['Texto CountVectorizer Unigrama e stopwords com arvore de decisão', score])\n",
        "print('Texto CountVectorizer Unigrama e stopwords com arvore de decisão:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texto CountVectorizer Unigrama e stopwords com arvore de decisão: 0.6878427159432746\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vsJU1_slAVsn",
        "outputId": "8321bd56-0e10-4096-e3d7-5539eb714e01"
      },
      "source": [
        "# Texto CountVectorizer Bigrama e stopwords com arvore de decisão\n",
        "# treinamento do modelo árvore de decisão\n",
        "tree = DecisionTreeClassifier(random_state=42)\n",
        "tree.fit(text_count2StopVect_train, df_train.sentimento)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "text_vect_test = text_count2StopVect.transform(df_test.texto)\n",
        "y_prediction = tree.predict(text_vect_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "score = f1_score(y_prediction, df_test.sentimento, average='weighted')\n",
        "resultado.append(['Texto CountVectorizer Bigrama e stopwords com arvore de decisão', score])\n",
        "print('Texto CountVectorizer Bigrama e stopwords com arvore de decisão:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texto CountVectorizer Bigrama e stopwords com arvore de decisão: 0.6689280197713933\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7YoTZmkAVsn",
        "outputId": "d575e1b8-eddf-4f95-ce1c-297112da8052"
      },
      "source": [
        "# Texto CountVectorizer Trigrama e stopwords com arvore de decisão\n",
        "# treinamento do modelo árvore de decisão\n",
        "tree = DecisionTreeClassifier(random_state=42)\n",
        "tree.fit(text_count3StopVect_train, df_train.sentimento)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "text_vect_test = text_count3StopVect.transform(df_test.texto)\n",
        "y_prediction = tree.predict(text_vect_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "score = f1_score(y_prediction, df_test.sentimento, average='weighted')\n",
        "resultado.append(['Texto CountVectorizer Trigrama e stopwords com arvore de decisão', score])\n",
        "print('Texto CountVectorizer Trigrama e stopwords com arvore de decisão:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texto CountVectorizer Trigrama e stopwords com arvore de decisão: 0.6578361325868657\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IcH_3e7tAVsn"
      },
      "source": [
        "##### TfidfVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LaUDJFT4AVsn",
        "outputId": "058fc444-df66-4a64-9065-dc97f10bc323"
      },
      "source": [
        "# Texto TfidfVectorizer Unigrama com arvore de decisão\n",
        "# treinamento do modelo árvore de decisão\n",
        "tree = DecisionTreeClassifier(random_state=42)\n",
        "tree.fit(text_tfidf1Vect_train, df_train.sentimento)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "text_vect_test = text_tfidf1Vect.transform(df_test.texto)\n",
        "y_prediction = tree.predict(text_vect_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "score = f1_score(y_prediction, df_test.sentimento, average='weighted')\n",
        "resultado.append(['Texto TfidfVectorizer Unigrama com arvore de decisão', score])\n",
        "print('Texto TfidfVectorizer Unigrama com arvore de decisão:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texto TfidfVectorizer Unigrama com arvore de decisão: 0.6560111726245649\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3tI8TvbAVsn",
        "outputId": "3ca89448-e4c6-48c9-d6b6-fea9b938c8fb"
      },
      "source": [
        "# Texto TfidfVectorizer Bigrama com arvore de decisão\n",
        "# treinamento do modelo árvore de decisão\n",
        "tree = DecisionTreeClassifier(random_state=42)\n",
        "tree.fit(text_tfidf2Vect_train, df_train.sentimento)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "text_vect_test = text_tfidf2Vect.transform(df_test.texto)\n",
        "y_prediction = tree.predict(text_vect_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "score = f1_score(y_prediction, df_test.sentimento, average='weighted')\n",
        "resultado.append(['Texto TfidfVectorizer Bigrama com arvore de decisão', score])\n",
        "print('Texto TfidfVectorizer Bigrama com arvore de decisão:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texto TfidfVectorizer Bigrama com arvore de decisão: 0.655388367729831\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GaaIbpbEAVso",
        "outputId": "35ab1bd3-4c86-4bfc-bbfc-5f037dce4f12"
      },
      "source": [
        "# Texto TfidfVectorizer Trigrama com arvore de decisão\n",
        "# treinamento do modelo árvore de decisão\n",
        "tree = DecisionTreeClassifier(random_state=42)\n",
        "tree.fit(text_tfidf3Vect_train, df_train.sentimento)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "text_vect_test = text_tfidf3Vect.transform(df_test.texto)\n",
        "y_prediction = tree.predict(text_vect_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "score = f1_score(y_prediction, df_test.sentimento, average='weighted')\n",
        "resultado.append(['Texto TfidfVectorizer Trigrama com arvore de decisão', score])\n",
        "print('Texto TfidfVectorizer Trigrama com arvore de decisão:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texto TfidfVectorizer Trigrama com arvore de decisão: 0.5798850574712644\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hMpz5VTAVso"
      },
      "source": [
        "##### TfidfVectorizer + Stopwords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJjX1wpaAVso",
        "outputId": "2ef6e0be-31cc-414d-af99-48a6b94ea9b7"
      },
      "source": [
        "# Texto TfidfVectorizer Unigrama e stopwords com arvore de decisão\n",
        "# treinamento do modelo árvore de decisão\n",
        "tree = DecisionTreeClassifier(random_state=42)\n",
        "tree.fit(text_tfidf1StopVect_train, df_train.sentimento)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "text_vect_test = text_tfidf1StopVect.transform(df_test.texto)\n",
        "y_prediction = tree.predict(text_vect_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "score = f1_score(y_prediction, df_test.sentimento, average='weighted')\n",
        "resultado.append(['Texto TfidfVectorizer Unigrama e stopwords com arvore de decisão', score])\n",
        "print('Texto TfidfVectorizer Unigrama e stopwords com arvore de decisão:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texto TfidfVectorizer Unigrama e stopwords com arvore de decisão: 0.6305554999499549\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h2HDcBwlAVso",
        "outputId": "77bdcf5a-f9bd-49c0-f1ad-41ed437a9f64"
      },
      "source": [
        "# Texto TfidfVectorizer Bigrama e stopwords com arvore de decisão\n",
        "# treinamento do modelo árvore de decisão\n",
        "tree = DecisionTreeClassifier(random_state=42)\n",
        "tree.fit(text_tfidf2StopVect_train, df_train.sentimento)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "text_vect_test = text_tfidf2StopVect.transform(df_test.texto)\n",
        "y_prediction = tree.predict(text_vect_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "score = f1_score(y_prediction, df_test.sentimento, average='weighted')\n",
        "resultado.append(['Texto TfidfVectorizer Bigrama e stopwords com arvore de decisão', score])\n",
        "print('Texto TfidfVectorizer Bigrama e stopwords com arvore de decisão:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texto TfidfVectorizer Bigrama e stopwords com arvore de decisão: 0.6302964743589743\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Atipt9EvAVso",
        "outputId": "bd108121-4071-4524-883b-db60a66cc8ec"
      },
      "source": [
        "# Texto TfidfVectorizer Trigrama e stopwords com arvore de decisão\n",
        "# treinamento do modelo árvore de decisão\n",
        "tree = DecisionTreeClassifier(random_state=42)\n",
        "tree.fit(text_tfidf3StopVect_train, df_train.sentimento)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "text_vect_test = text_tfidf3StopVect.transform(df_test.texto)\n",
        "y_prediction = tree.predict(text_vect_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "score = f1_score(y_prediction, df_test.sentimento, average='weighted')\n",
        "resultado.append(['Texto TfidfVectorizer Trigrama e stopwords com arvore de decisão', score])\n",
        "print('Texto TfidfVectorizer Trigrama e stopwords com arvore de decisão:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texto TfidfVectorizer Trigrama e stopwords com arvore de decisão: 0.6408363636363638\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4eiNR3eMOGH"
      },
      "source": [
        "#### RSLP Stemmer\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpS8ZcsTMOGP"
      },
      "source": [
        "##### CountVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5kgLXnBMOGP",
        "outputId": "a74bb3a2-6401-461a-f177-476eca3d09a1"
      },
      "source": [
        "# RSLP CountVectorizer Unigrama com arvore de decisão\n",
        "# treinamento do modelo árvore de decisão\n",
        "tree = DecisionTreeClassifier(random_state=42)\n",
        "tree.fit(rslp_count1Vect_train, df_train.sentimento)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "text_vect_test = rslp_count1Vect.transform(df_test.texto)\n",
        "y_prediction = tree.predict(text_vect_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "score = f1_score(y_prediction, df_test.sentimento, average='weighted')\n",
        "resultado.append(['RSLP CountVectorizer Unigrama com arvore de decisão', score])\n",
        "print('RSLP CountVectorizer Unigrama com arvore de decisão:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RSLP CountVectorizer Unigrama com arvore de decisão: 0.612313133634669\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNGtLMokMOGP",
        "outputId": "2d0a3e98-959f-434e-c194-edc8dfc66845"
      },
      "source": [
        "# RSLP CountVectorizer Bigrama com arvore de decisão\n",
        "# treinamento do modelo árvore de decisão\n",
        "tree = DecisionTreeClassifier(random_state=42)\n",
        "tree.fit(rslp_count2Vect_train, df_train.sentimento)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "text_vect_test = rslp_count2Vect.transform(df_test.texto)\n",
        "y_prediction = tree.predict(text_vect_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "score = f1_score(y_prediction, df_test.sentimento, average='weighted')\n",
        "resultado.append(['RSLP CountVectorizer Bigrama com arvore de decisão', score])\n",
        "print('RSLP CountVectorizer Bigrama com arvore de decisão:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RSLP CountVectorizer Bigrama com arvore de decisão: 0.6241909150757077\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-woAguNMOGQ",
        "outputId": "b7745a50-efd5-4396-dfaf-65c2b07045fd"
      },
      "source": [
        "# RSLP CountVectorizer Trigrama com arvore de decisão\n",
        "# treinamento do modelo árvore de decisão\n",
        "tree = DecisionTreeClassifier(random_state=42)\n",
        "tree.fit(rslp_count3Vect_train, df_train.sentimento)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "text_vect_test = rslp_count3Vect.transform(df_test.texto)\n",
        "y_prediction = tree.predict(text_vect_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "score = f1_score(y_prediction, df_test.sentimento, average='weighted')\n",
        "resultado.append(['RSLP CountVectorizer Trigrama com arvore de decisão', score])\n",
        "print('RSLP CountVectorizer Trigrama com arvore de decisão:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RSLP CountVectorizer Trigrama com arvore de decisão: 0.6217312120577768\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRAw7KtpMOGQ"
      },
      "source": [
        "##### CountVectorizer + Stopwords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHg3mcByMOGQ",
        "outputId": "b1f44de9-0eee-4079-a0dc-8c059a47fb77"
      },
      "source": [
        "# RSLP CountVectorizer Unigrama e stopwords com arvore de decisão\n",
        "# treinamento do modelo árvore de decisão\n",
        "tree = DecisionTreeClassifier(random_state=42)\n",
        "tree.fit(rslp_count1StopVect_train, df_train.sentimento)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "text_vect_test = rslp_count1StopVect.transform(df_test.texto)\n",
        "y_prediction = tree.predict(text_vect_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "score = f1_score(y_prediction, df_test.sentimento, average='weighted')\n",
        "resultado.append(['RSLP CountVectorizer Unigrama e stopwords com arvore de decisão', score])\n",
        "print('RSLP CountVectorizer Unigrama e stopwords com arvore de decisão:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RSLP CountVectorizer Unigrama e stopwords com arvore de decisão: 0.6547619047619048\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vOv5cooUMOGQ",
        "outputId": "37872fcf-475b-4f37-9699-c9b951c0275f"
      },
      "source": [
        "# RSLP CountVectorizer Bigrama e stopwords com arvore de decisão\n",
        "# treinamento do modelo árvore de decisão\n",
        "tree = DecisionTreeClassifier(random_state=42)\n",
        "tree.fit(rslp_count2StopVect_train, df_train.sentimento)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "text_vect_test = rslp_count2StopVect.transform(df_test.texto)\n",
        "y_prediction = tree.predict(text_vect_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "score = f1_score(y_prediction, df_test.sentimento, average='weighted')\n",
        "resultado.append(['RSLP CountVectorizer Bigrama e stopwords com arvore de decisão', score])\n",
        "print('RSLP CountVectorizer Bigrama e stopwords com arvore de decisão:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RSLP CountVectorizer Bigrama e stopwords com arvore de decisão: 0.6735751442353164\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrjPgRj9MOGQ",
        "outputId": "49db979b-8f8c-4a3d-e9ab-84b6302bed25"
      },
      "source": [
        "# RSLP CountVectorizer Trigrama e stopwords com arvore de decisão\n",
        "# treinamento do modelo árvore de decisão\n",
        "tree = DecisionTreeClassifier(random_state=42)\n",
        "tree.fit(rslp_count3StopVect_train, df_train.sentimento)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "text_vect_test = rslp_count3StopVect.transform(df_test.texto)\n",
        "y_prediction = tree.predict(text_vect_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "score = f1_score(y_prediction, df_test.sentimento, average='weighted')\n",
        "resultado.append(['RSLP CountVectorizer Trigrama e stopwords com arvore de decisão', score])\n",
        "print('RSLP CountVectorizer Trigrama e stopwords com arvore de decisão:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RSLP CountVectorizer Trigrama e stopwords com arvore de decisão: 0.6677408637873755\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGRwUg5DMOGR"
      },
      "source": [
        "##### TfidfVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvUKZBwtMOGR",
        "outputId": "0bf82a44-6191-4347-cac0-13f3f67fa110"
      },
      "source": [
        "# RSLP TfidfVectorizer Unigrama com arvore de decisão\n",
        "# treinamento do modelo árvore de decisão\n",
        "tree = DecisionTreeClassifier(random_state=42)\n",
        "tree.fit(rslp_tfidf1Vect_train, df_train.sentimento)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "text_vect_test = rslp_tfidf1Vect.transform(df_test.texto)\n",
        "y_prediction = tree.predict(text_vect_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "score = f1_score(y_prediction, df_test.sentimento, average='weighted')\n",
        "resultado.append(['RSLP TfidfVectorizer Unigrama com arvore de decisão', score])\n",
        "print('RSLP TfidfVectorizer Unigrama com arvore de decisão:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RSLP TfidfVectorizer Unigrama com arvore de decisão: 0.658819639735502\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1kP3tRIUMOGR",
        "outputId": "cda3eb65-a5a7-4019-ddf5-3a7bedccc39d"
      },
      "source": [
        "# RSLP TfidfVectorizer Bigrama com arvore de decisão\n",
        "# treinamento do modelo árvore de decisão\n",
        "tree = DecisionTreeClassifier(random_state=42)\n",
        "tree.fit(rslp_tfidf2Vect_train, df_train.sentimento)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "text_vect_test = rslp_tfidf2Vect.transform(df_test.texto)\n",
        "y_prediction = tree.predict(text_vect_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "score = f1_score(y_prediction, df_test.sentimento, average='weighted')\n",
        "resultado.append(['RSLP TfidfVectorizer Bigrama com arvore de decisão', score])\n",
        "print('RSLP TfidfVectorizer Bigrama com arvore de decisão:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RSLP TfidfVectorizer Bigrama com arvore de decisão: 0.6475524105048058\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCxRp0hQMOGR",
        "outputId": "67947129-a96b-4354-b598-e9648540cf8c"
      },
      "source": [
        "# RSLP TfidfVectorizer Trigrama com arvore de decisão\n",
        "# treinamento do modelo árvore de decisão\n",
        "tree = DecisionTreeClassifier(random_state=42)\n",
        "tree.fit(rslp_tfidf3Vect_train, df_train.sentimento)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "text_vect_test = rslp_tfidf3Vect.transform(df_test.texto)\n",
        "y_prediction = tree.predict(text_vect_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "score = f1_score(y_prediction, df_test.sentimento, average='weighted')\n",
        "resultado.append(['RSLP TfidfVectorizer Trigrama com arvore de decisão', score])\n",
        "print('RSLP TfidfVectorizer Trigrama com arvore de decisão:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RSLP TfidfVectorizer Trigrama com arvore de decisão: 0.6316574653416759\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTH2xdeRMOGR"
      },
      "source": [
        "##### TfidfVectorizer + Stopwords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eqxTVP4MOGR",
        "outputId": "782c100b-1792-4cdd-f3fd-e388d41c8ccb"
      },
      "source": [
        "# RSLP TfidfVectorizer Unigrama e stopwords com arvore de decisão\n",
        "# treinamento do modelo árvore de decisão\n",
        "tree = DecisionTreeClassifier(random_state=42)\n",
        "tree.fit(rslp_tfidf1StopVect_train, df_train.sentimento)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "text_vect_test = rslp_tfidf1StopVect.transform(df_test.texto)\n",
        "y_prediction = tree.predict(text_vect_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "score = f1_score(y_prediction, df_test.sentimento, average='weighted')\n",
        "resultado.append(['RSLP TfidfVectorizer Unigrama e stopwords com arvore de decisão', score])\n",
        "print('RSLP TfidfVectorizer Unigrama e stopwords com arvore de decisão:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RSLP TfidfVectorizer Unigrama e stopwords com arvore de decisão: 0.6309299483079117\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XbI7mfW6MOGS",
        "outputId": "ec2158b2-8d70-4615-9ce3-85036fc363be"
      },
      "source": [
        "# RSLP TfidfVectorizer Bigrama e stopwords com arvore de decisão\n",
        "# treinamento do modelo árvore de decisão\n",
        "tree = DecisionTreeClassifier(random_state=42)\n",
        "tree.fit(rslp_tfidf2StopVect_train, df_train.sentimento)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "text_vect_test = rslp_tfidf2StopVect.transform(df_test.texto)\n",
        "y_prediction = tree.predict(text_vect_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "score = f1_score(y_prediction, df_test.sentimento, average='weighted')\n",
        "resultado.append(['RSLP TfidfVectorizer Bigrama e stopwords com arvore de decisão', score])\n",
        "print('RSLP TfidfVectorizer Bigrama e stopwords com arvore de decisão:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RSLP TfidfVectorizer Bigrama e stopwords com arvore de decisão: 0.6735751442353164\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l57p_VKvMOGS",
        "outputId": "fc0ee660-ff21-4fcd-de86-dbccff5ad464"
      },
      "source": [
        "# RSLP TfidfVectorizer Trigrama e stopwords com arvore de decisão\n",
        "# treinamento do modelo árvore de decisão\n",
        "tree = DecisionTreeClassifier(random_state=42)\n",
        "tree.fit(rslp_tfidf3StopVect_train, df_train.sentimento)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "text_vect_test = rslp_tfidf3StopVect.transform(df_test.texto)\n",
        "y_prediction = tree.predict(text_vect_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "score = f1_score(y_prediction, df_test.sentimento, average='weighted')\n",
        "resultado.append(['RSLP TfidfVectorizer Trigrama e stopwords com arvore de decisão', score])\n",
        "print('RSLP TfidfVectorizer Trigrama e stopwords com arvore de decisão:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RSLP TfidfVectorizer Trigrama e stopwords com arvore de decisão: 0.6677408637873755\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSuUldn2MPCF"
      },
      "source": [
        "#### Snowball Stemmer\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRyIcxvEMPCF"
      },
      "source": [
        "##### CountVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wdig4sXMPCF",
        "outputId": "185a1e9f-9b1a-49f2-e134-48f7a89ac971"
      },
      "source": [
        "# Snowball CountVectorizer Unigrama com arvore de decisão\n",
        "# treinamento do modelo árvore de decisão\n",
        "tree = DecisionTreeClassifier(random_state=42)\n",
        "tree.fit(snow_count1Vect_train, df_train.sentimento)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "text_vect_test = snow_count1Vect.transform(df_test.texto)\n",
        "y_prediction = tree.predict(text_vect_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "score = f1_score(y_prediction, df_test.sentimento, average='weighted')\n",
        "resultado.append(['Snowball CountVectorizer Unigrama com arvore de decisão', score])\n",
        "print('Snowball CountVectorizer Unigrama com arvore de decisão:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Snowball CountVectorizer Unigrama com arvore de decisão: 0.6535\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zo6gGZjKMPCG",
        "outputId": "e584006d-70a4-4074-ef13-70d782bcb8cc"
      },
      "source": [
        "# Snowball CountVectorizer Bigrama com arvore de decisão\n",
        "# treinamento do modelo árvore de decisão\n",
        "tree = DecisionTreeClassifier(random_state=42)\n",
        "tree.fit(snow_count2Vect_train, df_train.sentimento)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "text_vect_test = snow_count2Vect.transform(df_test.texto)\n",
        "y_prediction = tree.predict(text_vect_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "score = f1_score(y_prediction, df_test.sentimento, average='weighted')\n",
        "resultado.append(['Snowball CountVectorizer Bigrama com arvore de decisão', score])\n",
        "print('Snowball CountVectorizer Bigrama com arvore de decisão:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Snowball CountVectorizer Bigrama com arvore de decisão: 0.6033650318452645\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1sU_aUnPMPCG",
        "outputId": "1674dffa-0d67-44ce-8e02-07cf56da659d"
      },
      "source": [
        "# Snowball CountVectorizer Trigrama com arvore de decisão\n",
        "# treinamento do modelo árvore de decisão\n",
        "tree = DecisionTreeClassifier(random_state=42)\n",
        "tree.fit(snow_count3Vect_train, df_train.sentimento)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "text_vect_test = snow_count3Vect.transform(df_test.texto)\n",
        "y_prediction = tree.predict(text_vect_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "score = f1_score(y_prediction, df_test.sentimento, average='weighted')\n",
        "resultado.append(['Snowball CountVectorizer Trigrama com arvore de decisão', score])\n",
        "print('Snowball CountVectorizer Trigrama com arvore de decisão:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Snowball CountVectorizer Trigrama com arvore de decisão: 0.628416877028489\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fc6nXbUmMPCG"
      },
      "source": [
        "##### CountVectorizer + Stopwords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZI2WgzepMPCG",
        "outputId": "6281e804-2fee-4ad2-87fe-d783cfe16f5f"
      },
      "source": [
        "# Snowball CountVectorizer Unigrama e stopwords com arvore de decisão\n",
        "# treinamento do modelo árvore de decisão\n",
        "tree = DecisionTreeClassifier(random_state=42)\n",
        "tree.fit(snow_count1StopVect_train, df_train.sentimento)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "text_vect_test = snow_count1StopVect.transform(df_test.texto)\n",
        "y_prediction = tree.predict(text_vect_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "score = f1_score(y_prediction, df_test.sentimento, average='weighted')\n",
        "resultado.append(['Snowball CountVectorizer Unigrama e stopwords com arvore de decisão', score])\n",
        "print('Snowball CountVectorizer Unigrama e stopwords com arvore de decisão:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Snowball CountVectorizer Unigrama e stopwords com arvore de decisão: 0.6442068965517241\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UM_5AoBKMPCG",
        "outputId": "12fb9617-4f1e-49ec-ecf9-888db4a60572"
      },
      "source": [
        "# Snowball CountVectorizer Bigrama e stopwords com arvore de decisão\n",
        "# treinamento do modelo árvore de decisão\n",
        "tree = DecisionTreeClassifier(random_state=42)\n",
        "tree.fit(snow_count2StopVect_train, df_train.sentimento)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "text_vect_test = snow_count2StopVect.transform(df_test.texto)\n",
        "y_prediction = tree.predict(text_vect_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "score = f1_score(y_prediction, df_test.sentimento, average='weighted')\n",
        "resultado.append(['Snowball CountVectorizer Bigrama e stopwords com arvore de decisão', score])\n",
        "print('Snowball CountVectorizer Bigrama e stopwords com arvore de decisão:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Snowball CountVectorizer Bigrama e stopwords com arvore de decisão: 0.6754966887417219\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_atZlIXMMPCG",
        "outputId": "ce61f6cf-b444-4731-e4d4-4835d037b2a3"
      },
      "source": [
        "# Snowball CountVectorizer Trigrama e stopwords com arvore de decisão\n",
        "# treinamento do modelo árvore de decisão\n",
        "tree = DecisionTreeClassifier(random_state=42)\n",
        "tree.fit(snow_count3StopVect_train, df_train.sentimento)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "text_vect_test = snow_count3StopVect.transform(df_test.texto)\n",
        "y_prediction = tree.predict(text_vect_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "score = f1_score(y_prediction, df_test.sentimento, average='weighted')\n",
        "resultado.append(['Snowball CountVectorizer Trigrama e stopwords com arvore de decisão', score])\n",
        "print('Snowball CountVectorizer Trigrama e stopwords com arvore de decisão:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Snowball CountVectorizer Trigrama e stopwords com arvore de decisão: 0.6677408637873755\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2p35LnFMPCG"
      },
      "source": [
        "##### TfidfVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUEK47NuMPCG",
        "outputId": "0e294fdd-5924-445f-e493-681b4e4d8f98"
      },
      "source": [
        "# Snowball TfidfVectorizer Unigrama com arvore de decisão\n",
        "# treinamento do modelo árvore de decisão\n",
        "tree = DecisionTreeClassifier(random_state=42)\n",
        "tree.fit(snow_tfidf1Vect_train, df_train.sentimento)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "text_vect_test = snow_tfidf1Vect.transform(df_test.texto)\n",
        "y_prediction = tree.predict(text_vect_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "score = f1_score(y_prediction, df_test.sentimento, average='weighted')\n",
        "resultado.append(['Snowball TfidfVectorizer Unigrama com arvore de decisão', score])\n",
        "print('Snowball TfidfVectorizer Unigrama com arvore de decisão:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Snowball TfidfVectorizer Unigrama com arvore de decisão: 0.6940265343544385\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5MLcfo7MPCH",
        "outputId": "c66ed59f-9439-4f0f-fd9b-546ca7a71766"
      },
      "source": [
        "# Snowball TfidfVectorizer Bigrama com arvore de decisão\n",
        "# treinamento do modelo árvore de decisão\n",
        "tree = DecisionTreeClassifier(random_state=42)\n",
        "tree.fit(snow_tfidf2Vect_train, df_train.sentimento)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "text_vect_test = snow_tfidf2Vect.transform(df_test.texto)\n",
        "y_prediction = tree.predict(text_vect_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "score = f1_score(y_prediction, df_test.sentimento, average='weighted')\n",
        "resultado.append(['Snowball TfidfVectorizer Bigrama com arvore de decisão', score])\n",
        "print('Snowball TfidfVectorizer Bigrama com arvore de decisão:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Snowball TfidfVectorizer Bigrama com arvore de decisão: 0.5285712443584785\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eNG0MWKmMPCH",
        "outputId": "9823b548-05f5-4454-c618-0d7a38a69e05"
      },
      "source": [
        "# Snowball TfidfVectorizer Trigrama com arvore de decisão\n",
        "# treinamento do modelo árvore de decisão\n",
        "tree = DecisionTreeClassifier(random_state=42)\n",
        "tree.fit(snow_tfidf3Vect_train, df_train.sentimento)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "text_vect_test = snow_tfidf3Vect.transform(df_test.texto)\n",
        "y_prediction = tree.predict(text_vect_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "score = f1_score(y_prediction, df_test.sentimento, average='weighted')\n",
        "resultado.append(['Snowball TfidfVectorizer Trigrama com arvore de decisão', score])\n",
        "print('Snowball TfidfVectorizer Trigrama com arvore de decisão:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Snowball TfidfVectorizer Trigrama com arvore de decisão: 0.612261089073206\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpe8kpA6MPCH"
      },
      "source": [
        "##### TfidfVectorizer + Stopwords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eu4g94wvMPCH",
        "outputId": "1abd1f7c-bc45-4efd-ac60-391b2fe48616"
      },
      "source": [
        "# Snowball TfidfVectorizer Unigrama e stopwords com arvore de decisão\n",
        "# treinamento do modelo árvore de decisão\n",
        "tree = DecisionTreeClassifier(random_state=42)\n",
        "tree.fit(snow_tfidf1StopVect_train, df_train.sentimento)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "text_vect_test = snow_tfidf1StopVect.transform(df_test.texto)\n",
        "y_prediction = tree.predict(text_vect_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "score = f1_score(y_prediction, df_test.sentimento, average='weighted')\n",
        "resultado.append(['Snowball TfidfVectorizer Unigrama e stopwords com arvore de decisão', score])\n",
        "print('Snowball TfidfVectorizer Unigrama e stopwords com arvore de decisão:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Snowball TfidfVectorizer Unigrama e stopwords com arvore de decisão: 0.632989898989899\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJv0sDkHMPCI",
        "outputId": "f40ed14c-2d23-4b48-cded-fb4dee120700"
      },
      "source": [
        "# Snowball TfidfVectorizer Bigrama e stopwords com arvore de decisão\n",
        "# treinamento do modelo árvore de decisão\n",
        "tree = DecisionTreeClassifier(random_state=42)\n",
        "tree.fit(snow_tfidf2StopVect_train, df_train.sentimento)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "text_vect_test = snow_tfidf2StopVect.transform(df_test.texto)\n",
        "y_prediction = tree.predict(text_vect_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "score = f1_score(y_prediction, df_test.sentimento, average='weighted')\n",
        "resultado.append(['Snowball TfidfVectorizer Bigrama e stopwords com arvore de decisão', score])\n",
        "print('Snowball TfidfVectorizer Bigrama e stopwords com arvore de decisão:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Snowball TfidfVectorizer Bigrama e stopwords com arvore de decisão: 0.6668\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GehJeK8hMPCI",
        "outputId": "7f2316e8-29fc-41b4-ad1d-b507dfc0bccd"
      },
      "source": [
        "# Snowball TfidfVectorizer Trigrama e stopwords com arvore de decisão\n",
        "# treinamento do modelo árvore de decisão\n",
        "tree = DecisionTreeClassifier(random_state=42)\n",
        "tree.fit(snow_tfidf3StopVect_train, df_train.sentimento)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "text_vect_test = snow_tfidf3StopVect.transform(df_test.texto)\n",
        "y_prediction = tree.predict(text_vect_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "score = f1_score(y_prediction, df_test.sentimento, average='weighted')\n",
        "resultado.append(['Snowball TfidfVectorizer Trigrama e stopwords com arvore de decisão', score])\n",
        "print('Snowball TfidfVectorizer Trigrama e stopwords com arvore de decisão:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Snowball TfidfVectorizer Trigrama e stopwords com arvore de decisão: 0.6677408637873755\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdsbjaGbuML9"
      },
      "source": [
        "#### Lemma\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3Lcr00PuMMF"
      },
      "source": [
        "##### CountVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xBZlGGoEuMMG",
        "outputId": "6a0628ee-d54b-405d-d220-25ac32f579fb"
      },
      "source": [
        "# Lemma CountVectorizer Unigrama com arvore de decisão\n",
        "# treinamento do modelo árvore de decisão\n",
        "tree = DecisionTreeClassifier(random_state=42)\n",
        "tree.fit(lemma_count1Vect_train, df_train.sentimento)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "text_vect_test = lemma_count1Vect.transform(df_test.texto)\n",
        "y_prediction = tree.predict(text_vect_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "score = f1_score(y_prediction, df_test.sentimento, average='weighted')\n",
        "resultado.append(['Lemma CountVectorizer Unigrama com arvore de decisão', score])\n",
        "print('Lemma CountVectorizer Unigrama com arvore de decisão:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Lemma CountVectorizer Unigrama com arvore de decisão: 0.6702974204884012\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6sye9KK0uMMG",
        "outputId": "c7db9d35-ac9c-441c-89a6-aa2f58cf778c"
      },
      "source": [
        "# Lemma CountVectorizer Bigrama com arvore de decisão\n",
        "# treinamento do modelo árvore de decisão\n",
        "tree = DecisionTreeClassifier(random_state=42)\n",
        "tree.fit(lemma_count2Vect_train, df_train.sentimento)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "text_vect_test = lemma_count2Vect.transform(df_test.texto)\n",
        "y_prediction = tree.predict(text_vect_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "score = f1_score(y_prediction, df_test.sentimento, average='weighted')\n",
        "resultado.append(['Lemma CountVectorizer Bigrama com arvore de decisão', score])\n",
        "print('Lemma CountVectorizer Bigrama com arvore de decisão:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Lemma CountVectorizer Bigrama com arvore de decisão: 0.595648452929559\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3H6uN9juMMH",
        "outputId": "4dab3a27-8c7d-4c6a-f526-54c059775f68"
      },
      "source": [
        "# Lemma CountVectorizer Trigrama com arvore de decisão\n",
        "# treinamento do modelo árvore de decisão\n",
        "tree = DecisionTreeClassifier(random_state=42)\n",
        "tree.fit(lemma_count3Vect_train, df_train.sentimento)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "text_vect_test = lemma_count3Vect.transform(df_test.texto)\n",
        "y_prediction = tree.predict(text_vect_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "score = f1_score(y_prediction, df_test.sentimento, average='weighted')\n",
        "resultado.append(['Lemma CountVectorizer Trigrama com arvore de decisão', score])\n",
        "print('Lemma CountVectorizer Trigrama com arvore de decisão:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Lemma CountVectorizer Trigrama com arvore de decisão: 0.6135963994138579\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0j-xDOVYuMMH"
      },
      "source": [
        "##### CountVectorizer + Stopwords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLyjMH4RuMMH",
        "outputId": "e01e5ec7-2548-4a67-b410-e3f2198aba6f"
      },
      "source": [
        "# Lemma CountVectorizer Unigrama e stopwords com arvore de decisão\n",
        "# treinamento do modelo árvore de decisão\n",
        "tree = DecisionTreeClassifier(random_state=42)\n",
        "tree.fit(lemma_count1StopVect_train, df_train.sentimento)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "text_vect_test = lemma_count1StopVect.transform(df_test.texto)\n",
        "y_prediction = tree.predict(text_vect_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "score = f1_score(y_prediction, df_test.sentimento, average='weighted')\n",
        "resultado.append(['Lemma CountVectorizer Unigrama e stopwords com arvore de decisão', score])\n",
        "print('Lemma CountVectorizer Unigrama e stopwords com arvore de decisão:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Lemma CountVectorizer Unigrama e stopwords com arvore de decisão: 0.6450543780265143\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNoMPEEluMMH",
        "outputId": "2e09d26e-ad34-4466-e776-82390d81ad2e"
      },
      "source": [
        "# Lemma CountVectorizer Bigrama e stopwords com arvore de decisão\n",
        "# treinamento do modelo árvore de decisão\n",
        "tree = DecisionTreeClassifier(random_state=42)\n",
        "tree.fit(lemma_count2StopVect_train, df_train.sentimento)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "text_vect_test = lemma_count2StopVect.transform(df_test.texto)\n",
        "y_prediction = tree.predict(text_vect_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "score = f1_score(y_prediction, df_test.sentimento, average='weighted')\n",
        "resultado.append(['Lemma CountVectorizer Bigrama e stopwords com arvore de decisão', score])\n",
        "print('Lemma CountVectorizer Bigrama e stopwords com arvore de decisão:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Lemma CountVectorizer Bigrama e stopwords com arvore de decisão: 0.6577130977130976\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1Cm0HYJuMMI",
        "outputId": "d1680b89-72a6-4d35-a1bd-d1865b6a4a47"
      },
      "source": [
        "# Lemma CountVectorizer Trigrama e stopwords com arvore de decisão\n",
        "# treinamento do modelo árvore de decisão\n",
        "tree = DecisionTreeClassifier(random_state=42)\n",
        "tree.fit(lemma_count3StopVect_train, df_train.sentimento)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "text_vect_test = lemma_count3StopVect.transform(df_test.texto)\n",
        "y_prediction = tree.predict(text_vect_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "score = f1_score(y_prediction, df_test.sentimento, average='weighted')\n",
        "resultado.append(['Lemma CountVectorizer Trigrama e stopwords com arvore de decisão', score])\n",
        "print('Lemma CountVectorizer Trigrama e stopwords com arvore de decisão:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Lemma CountVectorizer Trigrama e stopwords com arvore de decisão: 0.6754966887417219\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWwwQsmFuMMI"
      },
      "source": [
        "##### TfidfVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjIjZyW8uMMI",
        "outputId": "999484cd-0e1f-4b3c-82cb-4cec2ba10e59"
      },
      "source": [
        "# Lemma TfidfVectorizer Unigrama com arvore de decisão\n",
        "# treinamento do modelo árvore de decisão\n",
        "tree = DecisionTreeClassifier(random_state=42)\n",
        "tree.fit(lemma_tfidf1Vect_train, df_train.sentimento)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "text_vect_test = lemma_tfidf1Vect.transform(df_test.texto)\n",
        "y_prediction = tree.predict(text_vect_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "score = f1_score(y_prediction, df_test.sentimento, average='weighted')\n",
        "resultado.append(['Lemma TfidfVectorizer Unigrama com arvore de decisão', score])\n",
        "print('Lemma TfidfVectorizer Unigrama com arvore de decisão:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Lemma TfidfVectorizer Unigrama com arvore de decisão: 0.6488691796008869\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "idX9FdeKuMMI",
        "outputId": "b18e1a18-d523-4dbd-994b-3f68cc992e46"
      },
      "source": [
        "# Lemma TfidfVectorizer Bigrama com arvore de decisão\n",
        "# treinamento do modelo árvore de decisão\n",
        "tree = DecisionTreeClassifier(random_state=42)\n",
        "tree.fit(lemma_tfidf2Vect_train, df_train.sentimento)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "text_vect_test = lemma_tfidf2Vect.transform(df_test.texto)\n",
        "y_prediction = tree.predict(text_vect_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "score = f1_score(y_prediction, df_test.sentimento, average='weighted')\n",
        "resultado.append(['Lemma TfidfVectorizer Bigrama com arvore de decisão', score])\n",
        "print('Lemma TfidfVectorizer Bigrama com arvore de decisão:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Lemma TfidfVectorizer Bigrama com arvore de decisão: 0.635861491787844\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJDfJS6wuMMJ",
        "outputId": "08a09f3a-c8d8-4e9a-f1ce-b1e7eb60be6c"
      },
      "source": [
        "# Lemma TfidfVectorizer Trigrama com arvore de decisão\n",
        "# treinamento do modelo árvore de decisão\n",
        "tree = DecisionTreeClassifier(random_state=42)\n",
        "tree.fit(lemma_tfidf3Vect_train, df_train.sentimento)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "text_vect_test = lemma_tfidf3Vect.transform(df_test.texto)\n",
        "y_prediction = tree.predict(text_vect_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "score = f1_score(y_prediction, df_test.sentimento, average='weighted')\n",
        "resultado.append(['Lemma TfidfVectorizer Trigrama com arvore de decisão', score])\n",
        "print('Lemma TfidfVectorizer Trigrama com arvore de decisão:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Lemma TfidfVectorizer Trigrama com arvore de decisão: 0.6298660247016956\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVTq5QEduMMJ"
      },
      "source": [
        "##### TfidfVectorizer + Stopwords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilDIii8buMMJ",
        "outputId": "1b4e151b-71ab-403f-a17f-69a75b1d7739"
      },
      "source": [
        "# Lemma TfidfVectorizer Unigrama e stopwords com arvore de decisão\n",
        "# treinamento do modelo árvore de decisão\n",
        "tree = DecisionTreeClassifier(random_state=42)\n",
        "tree.fit(lemma_tfidf1StopVect_train, df_train.sentimento)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "text_vect_test = lemma_tfidf1StopVect.transform(df_test.texto)\n",
        "y_prediction = tree.predict(text_vect_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "score = f1_score(y_prediction, df_test.sentimento, average='weighted')\n",
        "resultado.append(['Lemma TfidfVectorizer Unigrama e stopwords com arvore de decisão', score])\n",
        "print('Lemma TfidfVectorizer Unigrama e stopwords com arvore de decisão:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Lemma TfidfVectorizer Unigrama e stopwords com arvore de decisão: 0.6910903426791277\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBaWD23nuMMJ",
        "outputId": "fee01cdd-98b5-47ab-cfc4-81770197086c"
      },
      "source": [
        "# Lemma TfidfVectorizer Bigrama e stopwords com arvore de decisão\n",
        "# treinamento do modelo árvore de decisão\n",
        "tree = DecisionTreeClassifier(random_state=42)\n",
        "tree.fit(lemma_tfidf2StopVect_train, df_train.sentimento)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "text_vect_test = lemma_tfidf2StopVect.transform(df_test.texto)\n",
        "y_prediction = tree.predict(text_vect_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "score = f1_score(y_prediction, df_test.sentimento, average='weighted')\n",
        "resultado.append(['Lemma TfidfVectorizer Bigrama e stopwords com arvore de decisão', score])\n",
        "print('Lemma TfidfVectorizer Bigrama e stopwords com arvore de decisão:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Lemma TfidfVectorizer Bigrama e stopwords com arvore de decisão: 0.6650730607041289\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqfxpoRLuMMJ",
        "outputId": "061e3c4b-70e2-40d2-ea2e-ea166af0fc51"
      },
      "source": [
        "# Lemma TfidfVectorizer Trigrama e stopwords com arvore de decisão\n",
        "# treinamento do modelo árvore de decisão\n",
        "tree = DecisionTreeClassifier(random_state=42)\n",
        "tree.fit(lemma_tfidf3StopVect_train, df_train.sentimento)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "text_vect_test = lemma_tfidf3StopVect.transform(df_test.texto)\n",
        "y_prediction = tree.predict(text_vect_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "score = f1_score(y_prediction, df_test.sentimento, average='weighted')\n",
        "resultado.append(['Lemma TfidfVectorizer Trigrama e stopwords com arvore de decisão', score])\n",
        "print('Lemma TfidfVectorizer Trigrama e stopwords com arvore de decisão:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Lemma TfidfVectorizer Trigrama e stopwords com arvore de decisão: 0.6668\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cytiQwJxiHgj"
      },
      "source": [
        "### Naive Bayes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CglYqDOFiHgq"
      },
      "source": [
        "#### Texto\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNLJ18BEiHgq"
      },
      "source": [
        "##### CountVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AavhR2JuiHgq",
        "outputId": "84fbbb3d-027a-4a10-8dd0-71e1866cc318"
      },
      "source": [
        "# Texto CountVectorizer Unigrama com Naive Bayes\n",
        "# treinamento do modelo Naive Bayes\n",
        "bayes = MultinomialNB()\n",
        "bayes.fit(text_count1Vect_train, df_train.sentimento)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "text_vect_test = text_count1Vect.transform(df_test.texto)\n",
        "y_prediction = bayes.predict(text_vect_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "score = f1_score(y_prediction, df_test.sentimento, average='weighted')\n",
        "resultado.append(['Texto CountVectorizer Unigrama com Naive Bayes', score])\n",
        "print('Texto CountVectorizer Unigrama com Naive Bayes:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texto CountVectorizer Unigrama com Naive Bayes: 0.7951076492210748\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fezcJHDmiHgr",
        "outputId": "817aa371-4a1a-477a-8761-db1cb09c2e4f"
      },
      "source": [
        "# Texto CountVectorizer Bigrama com Naive Bayes\n",
        "# treinamento do modelo Naive Bayes\n",
        "bayes = MultinomialNB()\n",
        "bayes.fit(text_count2Vect_train, df_train.sentimento)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "text_vect_test = text_count2Vect.transform(df_test.texto)\n",
        "y_prediction = bayes.predict(text_vect_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "score = f1_score(y_prediction, df_test.sentimento, average='weighted')\n",
        "resultado.append(['Texto CountVectorizer Bigrama com Naive Bayes', score])\n",
        "print('Texto CountVectorizer Bigrama com Naive Bayes:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texto CountVectorizer Bigrama com Naive Bayes: 0.8001600640256101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFpBRMI0iHgr",
        "outputId": "4315fca6-fc58-4432-d76b-a17a8f4f38ed"
      },
      "source": [
        "# Texto CountVectorizer Trigrama com Naive Bayes\n",
        "# treinamento do modelo Naive Bayes\n",
        "bayes = MultinomialNB()\n",
        "bayes.fit(text_count3Vect_train, df_train.sentimento)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "text_vect_test = text_count3Vect.transform(df_test.texto)\n",
        "y_prediction = bayes.predict(text_vect_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "score = f1_score(y_prediction, df_test.sentimento, average='weighted')\n",
        "resultado.append(['Texto CountVectorizer Trigrama com Naive Bayes', score])\n",
        "print('Texto CountVectorizer Trigrama com Naive Bayes:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texto CountVectorizer Trigrama com Naive Bayes: 0.7200840756681012\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loj_Qol5iHgs"
      },
      "source": [
        "##### CountVectorizer + Stopwords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_K2PjoSiHgs",
        "outputId": "60fb6e0c-719e-4353-f964-61200560f2e8"
      },
      "source": [
        "# Texto CountVectorizer Unigrama e stopwords com Naive Bayes\n",
        "# treinamento do modelo Naive Bayes\n",
        "bayes = MultinomialNB()\n",
        "bayes.fit(text_count1StopVect_train, df_train.sentimento)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "text_vect_test = text_count1StopVect.transform(df_test.texto)\n",
        "y_prediction = bayes.predict(text_vect_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "score = f1_score(y_prediction, df_test.sentimento, average='weighted')\n",
        "resultado.append(['Texto CountVectorizer Unigrama e stopwords com Naive Bayes', score])\n",
        "print('Texto CountVectorizer Unigrama e stopwords com Naive Bayes:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texto CountVectorizer Unigrama e stopwords com Naive Bayes: 0.7900630063006301\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjR0uA8xiHgs",
        "outputId": "3330276a-da92-42f6-862d-1a47169f3fc2"
      },
      "source": [
        "# Texto CountVectorizer Bigrama e stopwords com Naive Bayes\n",
        "# treinamento do modelo Naive Bayes\n",
        "bayes = MultinomialNB()\n",
        "bayes.fit(text_count2StopVect_train, df_train.sentimento)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "text_vect_test = text_count2StopVect.transform(df_test.texto)\n",
        "y_prediction = bayes.predict(text_vect_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "score = f1_score(y_prediction, df_test.sentimento, average='weighted')\n",
        "resultado.append(['Texto CountVectorizer Bigrama e stopwords com Naive Bayes', score])\n",
        "print('Texto CountVectorizer Bigrama e stopwords com Naive Bayes:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texto CountVectorizer Bigrama e stopwords com Naive Bayes: 0.744980874521863\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQW5TeYYiHgs",
        "outputId": "56b81112-d789-4579-d076-5ab0535c410f"
      },
      "source": [
        "# Texto CountVectorizer Trigrama e stopwords com Naive Bayes\n",
        "# treinamento do modelo Naive Bayes\n",
        "bayes = MultinomialNB()\n",
        "bayes.fit(text_count3StopVect_train, df_train.sentimento)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "text_vect_test = text_count3StopVect.transform(df_test.texto)\n",
        "y_prediction = bayes.predict(text_vect_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "score = f1_score(y_prediction, df_test.sentimento, average='weighted')\n",
        "resultado.append(['Texto CountVectorizer Trigrama e stopwords com Naive Bayes', score])\n",
        "print('Texto CountVectorizer Trigrama e stopwords com Naive Bayes:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texto CountVectorizer Trigrama e stopwords com Naive Bayes: 0.643977024491789\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6z5w5HvViHgt"
      },
      "source": [
        "##### TfidfVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNH18VZKiHgt",
        "outputId": "397810a0-fe50-45e7-8d50-20aba6395c0e"
      },
      "source": [
        "# Texto TfidfVectorizer Unigrama com Naive Bayes\n",
        "# treinamento do modelo Naive Bayes\n",
        "bayes = MultinomialNB()\n",
        "bayes.fit(text_tfidf1Vect_train, df_train.sentimento)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "text_vect_test = text_tfidf1Vect.transform(df_test.texto)\n",
        "y_prediction = bayes.predict(text_vect_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "score = f1_score(y_prediction, df_test.sentimento, average='weighted')\n",
        "resultado.append(['Texto TfidfVectorizer Unigrama com Naive Bayes', score])\n",
        "print('Texto TfidfVectorizer Unigrama com Naive Bayes:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texto TfidfVectorizer Unigrama com Naive Bayes: 0.799395220164451\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ns88YZ6KiHgt",
        "outputId": "89e865f5-89ea-46d0-f549-57a99fbcaf65"
      },
      "source": [
        "# Texto TfidfVectorizer Bigrama com Naive Bayes\n",
        "# treinamento do modelo Naive Bayes\n",
        "bayes = MultinomialNB()\n",
        "bayes.fit(text_tfidf2Vect_train, df_train.sentimento)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "text_vect_test = text_tfidf2Vect.transform(df_test.texto)\n",
        "y_prediction = bayes.predict(text_vect_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "score = f1_score(y_prediction, df_test.sentimento, average='weighted')\n",
        "resultado.append(['Texto TfidfVectorizer Bigrama com Naive Bayes', score])\n",
        "print('Texto TfidfVectorizer Bigrama com Naive Bayes:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texto TfidfVectorizer Bigrama com Naive Bayes: 0.7910161186331399\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbOW2TjPiHgt",
        "outputId": "2f10f357-99bf-434a-c9e7-2029b00dfdfe"
      },
      "source": [
        "# Texto TfidfVectorizer Trigrama com Naive Bayes\n",
        "# treinamento do modelo Naive Bayes\n",
        "bayes = MultinomialNB()\n",
        "bayes.fit(text_tfidf3Vect_train, df_train.sentimento)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "text_vect_test = text_tfidf3Vect.transform(df_test.texto)\n",
        "y_prediction = bayes.predict(text_vect_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "score = f1_score(y_prediction, df_test.sentimento, average='weighted')\n",
        "resultado.append(['Texto TfidfVectorizer Trigrama com Naive Bayes', score])\n",
        "print('Texto TfidfVectorizer Trigrama com Naive Bayes:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texto TfidfVectorizer Trigrama com Naive Bayes: 0.72230032713636\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBeDtIfWiHgt"
      },
      "source": [
        "##### TfidfVectorizer + Stopwords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCdPEFytiHgu",
        "outputId": "aab22612-de1f-41b2-9668-e4b2b2dff1cb"
      },
      "source": [
        "# Texto TfidfVectorizer Unigrama e stopwords com Naive Bayes\n",
        "# treinamento do modelo Naive Bayes\n",
        "bayes = MultinomialNB()\n",
        "bayes.fit(text_tfidf1StopVect_train, df_train.sentimento)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "text_vect_test = text_tfidf1StopVect.transform(df_test.texto)\n",
        "y_prediction = bayes.predict(text_vect_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "score = f1_score(y_prediction, df_test.sentimento, average='weighted')\n",
        "resultado.append(['Texto TfidfVectorizer Unigrama e stopwords com Naive Bayes', score])\n",
        "print('Texto TfidfVectorizer Unigrama e stopwords com Naive Bayes:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texto TfidfVectorizer Unigrama e stopwords com Naive Bayes: 0.7739412484700123\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwb5bBmciHgu",
        "outputId": "58aacbea-edd5-47b5-b845-4e7e1649a508"
      },
      "source": [
        "# Texto TfidfVectorizer Bigrama e stopwords com Naive Bayes\n",
        "# treinamento do modelo Naive Bayes\n",
        "bayes = MultinomialNB()\n",
        "bayes.fit(text_tfidf2StopVect_train, df_train.sentimento)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "text_vect_test = text_tfidf2StopVect.transform(df_test.texto)\n",
        "y_prediction = bayes.predict(text_vect_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "score = f1_score(y_prediction, df_test.sentimento, average='weighted')\n",
        "resultado.append(['Texto TfidfVectorizer Bigrama e stopwords com Naive Bayes', score])\n",
        "print('Texto TfidfVectorizer Bigrama e stopwords com Naive Bayes:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texto TfidfVectorizer Bigrama e stopwords com Naive Bayes: 0.7431655844155844\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vd98yKX3iHgu",
        "outputId": "590a0693-e006-4d8b-92b9-47796242387d"
      },
      "source": [
        "# Texto TfidfVectorizer Trigrama e stopwords com Naive Bayes\n",
        "# treinamento do modelo Naive Bayes\n",
        "bayes = MultinomialNB()\n",
        "bayes.fit(text_tfidf3StopVect_train, df_train.sentimento)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "text_vect_test = text_tfidf3StopVect.transform(df_test.texto)\n",
        "y_prediction = bayes.predict(text_vect_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "score = f1_score(y_prediction, df_test.sentimento, average='weighted')\n",
        "resultado.append(['Texto TfidfVectorizer Trigrama e stopwords com Naive Bayes', score])\n",
        "print('Texto TfidfVectorizer Trigrama e stopwords com Naive Bayes:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texto TfidfVectorizer Trigrama e stopwords com Naive Bayes: 0.6433066666666666\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LegkemmJiHgu"
      },
      "source": [
        "#### RSLP Stemmer\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqCZkgQ6iHgv"
      },
      "source": [
        "##### CountVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BoZM5fOLiHgw",
        "outputId": "9e0a9c1c-56cf-4860-87e9-b2509360d284"
      },
      "source": [
        "# RSLP CountVectorizer Unigrama com Naive Bayes\n",
        "# treinamento do modelo Naive Bayes\n",
        "bayes = MultinomialNB()\n",
        "bayes.fit(rslp_count1Vect_train, df_train.sentimento)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "text_vect_test = rslp_count1Vect.transform(df_test.texto)\n",
        "y_prediction = bayes.predict(text_vect_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "score = f1_score(y_prediction, df_test.sentimento, average='weighted')\n",
        "resultado.append(['RSLP CountVectorizer Unigrama com Naive Bayes', score])\n",
        "print('RSLP CountVectorizer Unigrama com Naive Bayes:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RSLP CountVectorizer Unigrama com Naive Bayes: 0.6881387802867097\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejvzw_j7iHgw",
        "outputId": "778e233e-9f04-44f0-f686-e146d69b756c"
      },
      "source": [
        "# RSLP CountVectorizer Bigrama com Naive Bayes\n",
        "# treinamento do modelo Naive Bayes\n",
        "bayes = MultinomialNB()\n",
        "bayes.fit(rslp_count2Vect_train, df_train.sentimento)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "text_vect_test = rslp_count2Vect.transform(df_test.texto)\n",
        "y_prediction = bayes.predict(text_vect_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "score = f1_score(y_prediction, df_test.sentimento, average='weighted')\n",
        "resultado.append(['RSLP CountVectorizer Bigrama com Naive Bayes', score])\n",
        "print('RSLP CountVectorizer Bigrama com Naive Bayes:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RSLP CountVectorizer Bigrama com Naive Bayes: 0.6595786041103162\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "blLaaveSiHgx",
        "outputId": "9abfbfdc-a668-4ad0-81fd-40d157272c35"
      },
      "source": [
        "# RSLP CountVectorizer Trigrama com Naive Bayes\n",
        "# treinamento do modelo Naive Bayes\n",
        "bayes = MultinomialNB()\n",
        "bayes.fit(rslp_count3Vect_train, df_train.sentimento)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "text_vect_test = rslp_count3Vect.transform(df_test.texto)\n",
        "y_prediction = bayes.predict(text_vect_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "score = f1_score(y_prediction, df_test.sentimento, average='weighted')\n",
        "resultado.append(['RSLP CountVectorizer Trigrama com Naive Bayes', score])\n",
        "print('RSLP CountVectorizer Trigrama com Naive Bayes:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RSLP CountVectorizer Trigrama com Naive Bayes: 0.6218357487922705\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKs_U8J7iHgx"
      },
      "source": [
        "##### CountVectorizer + Stopwords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJtuxOTCiHgx",
        "outputId": "641b1290-641e-40ca-a466-0a3b7565880b"
      },
      "source": [
        "# RSLP CountVectorizer Unigrama e stopwords com Naive Bayes\n",
        "# treinamento do modelo Naive Bayes\n",
        "bayes = MultinomialNB()\n",
        "bayes.fit(rslp_count1StopVect_train, df_train.sentimento)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "text_vect_test = rslp_count1StopVect.transform(df_test.texto)\n",
        "y_prediction = bayes.predict(text_vect_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "score = f1_score(y_prediction, df_test.sentimento, average='weighted')\n",
        "resultado.append(['RSLP CountVectorizer Unigrama e stopwords com Naive Bayes', score])\n",
        "print('RSLP CountVectorizer Unigrama e stopwords com Naive Bayes:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RSLP CountVectorizer Unigrama e stopwords com Naive Bayes: 0.672140001527845\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_BSRD_PiHgx",
        "outputId": "0929e569-af04-499e-a3f9-4b63c0f8e12e"
      },
      "source": [
        "# RSLP CountVectorizer Bigrama e stopwords com Naive Bayes\n",
        "# treinamento do modelo Naive Bayes\n",
        "bayes = MultinomialNB()\n",
        "bayes.fit(rslp_count2StopVect_train, df_train.sentimento)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "text_vect_test = rslp_count2StopVect.transform(df_test.texto)\n",
        "y_prediction = bayes.predict(text_vect_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "score = f1_score(y_prediction, df_test.sentimento, average='weighted')\n",
        "resultado.append(['RSLP CountVectorizer Bigrama e stopwords com Naive Bayes', score])\n",
        "print('RSLP CountVectorizer Bigrama e stopwords com Naive Bayes:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RSLP CountVectorizer Bigrama e stopwords com Naive Bayes: 0.6223629786899426\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ge4XnGvXiHgx",
        "outputId": "738683bf-822d-47ad-af16-497a900a8475"
      },
      "source": [
        "# RSLP CountVectorizer Trigrama e stopwords com Naive Bayes\n",
        "# treinamento do modelo Naive Bayes\n",
        "bayes = MultinomialNB()\n",
        "bayes.fit(rslp_count3StopVect_train, df_train.sentimento)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "text_vect_test = rslp_count3StopVect.transform(df_test.texto)\n",
        "y_prediction = bayes.predict(text_vect_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "score = f1_score(y_prediction, df_test.sentimento, average='weighted')\n",
        "resultado.append(['RSLP CountVectorizer Trigrama e stopwords com Naive Bayes', score])\n",
        "print('RSLP CountVectorizer Trigrama e stopwords com Naive Bayes:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RSLP CountVectorizer Trigrama e stopwords com Naive Bayes: 0.6650730607041289\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXMqNqMliHgy"
      },
      "source": [
        "##### TfidfVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mEleRriLiHgy",
        "outputId": "f1eb8b7b-fbf7-4b2d-e99a-1759947a55b4"
      },
      "source": [
        "# RSLP TfidfVectorizer Unigrama com Naive Bayes\n",
        "# treinamento do modelo Naive Bayes\n",
        "bayes = MultinomialNB()\n",
        "bayes.fit(rslp_tfidf1Vect_train, df_train.sentimento)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "text_vect_test = rslp_tfidf1Vect.transform(df_test.texto)\n",
        "y_prediction = bayes.predict(text_vect_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "score = f1_score(y_prediction, df_test.sentimento, average='weighted')\n",
        "resultado.append(['RSLP TfidfVectorizer Unigrama com Naive Bayes', score])\n",
        "print('RSLP TfidfVectorizer Unigrama com Naive Bayes:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RSLP TfidfVectorizer Unigrama com Naive Bayes: 0.6713932980599647\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFiLqRk2iHgy",
        "outputId": "f5d47a6e-44e0-4171-ff22-0311b8eeb92a"
      },
      "source": [
        "# RSLP TfidfVectorizer Bigrama com Naive Bayes\n",
        "# treinamento do modelo Naive Bayes\n",
        "bayes = MultinomialNB()\n",
        "bayes.fit(rslp_tfidf2Vect_train, df_train.sentimento)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "text_vect_test = rslp_tfidf2Vect.transform(df_test.texto)\n",
        "y_prediction = bayes.predict(text_vect_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "score = f1_score(y_prediction, df_test.sentimento, average='weighted')\n",
        "resultado.append(['RSLP TfidfVectorizer Bigrama com Naive Bayes', score])\n",
        "print('RSLP TfidfVectorizer Bigrama com Naive Bayes:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RSLP TfidfVectorizer Bigrama com Naive Bayes: 0.6354932301740811\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9GDjrPnqiHgy",
        "outputId": "a07eba05-ce9a-4806-e04d-bb4874f23c2d"
      },
      "source": [
        "# RSLP TfidfVectorizer Trigrama com Naive Bayes\n",
        "# treinamento do modelo Naive Bayes\n",
        "bayes = MultinomialNB()\n",
        "bayes.fit(rslp_tfidf3Vect_train, df_train.sentimento)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "text_vect_test = rslp_tfidf3Vect.transform(df_test.texto)\n",
        "y_prediction = bayes.predict(text_vect_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "score = f1_score(y_prediction, df_test.sentimento, average='weighted')\n",
        "resultado.append(['RSLP TfidfVectorizer Trigrama com Naive Bayes', score])\n",
        "print('RSLP TfidfVectorizer Trigrama com Naive Bayes:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RSLP TfidfVectorizer Trigrama com Naive Bayes: 0.6007578025087752\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UJ5VdnxiHgy"
      },
      "source": [
        "##### TfidfVectorizer + Stopwords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edY7PQkyiHgy",
        "outputId": "c0027612-d303-416a-e9c3-1c2971cce0ba"
      },
      "source": [
        "# RSLP TfidfVectorizer Unigrama e stopwords com Naive Bayes\n",
        "# treinamento do modelo Naive Bayes\n",
        "bayes = MultinomialNB()\n",
        "bayes.fit(rslp_tfidf1StopVect_train, df_train.sentimento)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "text_vect_test = rslp_tfidf1StopVect.transform(df_test.texto)\n",
        "y_prediction = bayes.predict(text_vect_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "score = f1_score(y_prediction, df_test.sentimento, average='weighted')\n",
        "resultado.append(['RSLP TfidfVectorizer Unigrama e stopwords com Naive Bayes', score])\n",
        "print('RSLP TfidfVectorizer Unigrama e stopwords com Naive Bayes:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RSLP TfidfVectorizer Unigrama e stopwords com Naive Bayes: 0.635861491787844\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzymZWrJiHgz",
        "outputId": "06802c0f-1a51-4b72-e4f6-165d0634db58"
      },
      "source": [
        "# RSLP TfidfVectorizer Bigrama e stopwords com Naive Bayes\n",
        "# treinamento do modelo Naive Bayes\n",
        "bayes = MultinomialNB()\n",
        "bayes.fit(rslp_tfidf2StopVect_train, df_train.sentimento)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "text_vect_test = rslp_tfidf2StopVect.transform(df_test.texto)\n",
        "y_prediction = bayes.predict(text_vect_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "score = f1_score(y_prediction, df_test.sentimento, average='weighted')\n",
        "resultado.append(['RSLP TfidfVectorizer Bigrama e stopwords com Naive Bayes', score])\n",
        "print('RSLP TfidfVectorizer Bigrama e stopwords com Naive Bayes:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RSLP TfidfVectorizer Bigrama e stopwords com Naive Bayes: 0.618843495878549\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TD8U5vH5iHgz",
        "outputId": "0475173e-8064-4977-a0a1-8d74aaf979db"
      },
      "source": [
        "# RSLP TfidfVectorizer Trigrama e stopwords com Naive Bayes\n",
        "# treinamento do modelo Naive Bayes\n",
        "bayes = MultinomialNB()\n",
        "bayes.fit(rslp_tfidf3StopVect_train, df_train.sentimento)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "text_vect_test = rslp_tfidf3StopVect.transform(df_test.texto)\n",
        "y_prediction = bayes.predict(text_vect_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "score = f1_score(y_prediction, df_test.sentimento, average='weighted')\n",
        "resultado.append(['RSLP TfidfVectorizer Trigrama e stopwords com Naive Bayes', score])\n",
        "print('RSLP TfidfVectorizer Trigrama e stopwords com Naive Bayes:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RSLP TfidfVectorizer Trigrama e stopwords com Naive Bayes: 0.6650730607041289\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1N9YBQxiHgz"
      },
      "source": [
        "#### Snowball Stemmer\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBt_HELXiHgz"
      },
      "source": [
        "##### CountVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9O6rewaiHgz",
        "outputId": "d4f70380-fa05-4590-c662-596f7a0d503c"
      },
      "source": [
        "# Snowball CountVectorizer Unigrama com Naive Bayes\n",
        "# treinamento do modelo Naive Bayes\n",
        "bayes = MultinomialNB()\n",
        "bayes.fit(snow_count1Vect_train, df_train.sentimento)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "text_vect_test = snow_count1Vect.transform(df_test.texto)\n",
        "y_prediction = bayes.predict(text_vect_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "score = f1_score(y_prediction, df_test.sentimento, average='weighted')\n",
        "resultado.append(['Snowball CountVectorizer Unigrama com Naive Bayes', score])\n",
        "print('Snowball CountVectorizer Unigrama com Naive Bayes:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Snowball CountVectorizer Unigrama com Naive Bayes: 0.7059505645407385\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6NPX_ByviHgz",
        "outputId": "f8e12e67-0456-4b77-9337-eb5d26a777ef"
      },
      "source": [
        "# Snowball CountVectorizer Bigrama com Naive Bayes\n",
        "# treinamento do modelo Naive Bayes\n",
        "bayes = MultinomialNB()\n",
        "bayes.fit(snow_count2Vect_train, df_train.sentimento)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "text_vect_test = snow_count2Vect.transform(df_test.texto)\n",
        "y_prediction = bayes.predict(text_vect_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "score = f1_score(y_prediction, df_test.sentimento, average='weighted')\n",
        "resultado.append(['Snowball CountVectorizer Bigrama com Naive Bayes', score])\n",
        "print('Snowball CountVectorizer Bigrama com Naive Bayes:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Snowball CountVectorizer Bigrama com Naive Bayes: 0.6299629962996299\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3U2wbAyViHgz",
        "outputId": "06f03ab5-d436-407f-ccee-bccc01122e2d"
      },
      "source": [
        "# Snowball CountVectorizer Trigrama com Naive Bayes\n",
        "# treinamento do modelo Naive Bayes\n",
        "bayes = MultinomialNB()\n",
        "bayes.fit(snow_count3Vect_train, df_train.sentimento)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "text_vect_test = snow_count3Vect.transform(df_test.texto)\n",
        "y_prediction = bayes.predict(text_vect_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "score = f1_score(y_prediction, df_test.sentimento, average='weighted')\n",
        "resultado.append(['Snowball CountVectorizer Trigrama com Naive Bayes', score])\n",
        "print('Snowball CountVectorizer Trigrama com Naive Bayes:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Snowball CountVectorizer Trigrama com Naive Bayes: 0.5701291162045841\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0fBG3M5iHg0"
      },
      "source": [
        "##### CountVectorizer + Stopwords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yMR28UWbiHg0",
        "outputId": "a5a2a783-535b-4307-f3ca-8f0b904e7432"
      },
      "source": [
        "# Snowball CountVectorizer Unigrama e stopwords com Naive Bayes\n",
        "# treinamento do modelo Naive Bayes\n",
        "bayes = MultinomialNB()\n",
        "bayes.fit(snow_count1StopVect_train, df_train.sentimento)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "text_vect_test = snow_count1StopVect.transform(df_test.texto)\n",
        "y_prediction = bayes.predict(text_vect_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "score = f1_score(y_prediction, df_test.sentimento, average='weighted')\n",
        "resultado.append(['Snowball CountVectorizer Unigrama e stopwords com Naive Bayes', score])\n",
        "print('Snowball CountVectorizer Unigrama e stopwords com Naive Bayes:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Snowball CountVectorizer Unigrama e stopwords com Naive Bayes: 0.6605104594134721\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_4SBisfiHg1",
        "outputId": "4c4940d6-2800-40f7-a62a-45f4e5b7e5eb"
      },
      "source": [
        "# Snowball CountVectorizer Bigrama e stopwords com Naive Bayes\n",
        "# treinamento do modelo Naive Bayes\n",
        "bayes = MultinomialNB()\n",
        "bayes.fit(snow_count2StopVect_train, df_train.sentimento)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "text_vect_test = snow_count2StopVect.transform(df_test.texto)\n",
        "y_prediction = bayes.predict(text_vect_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "score = f1_score(y_prediction, df_test.sentimento, average='weighted')\n",
        "resultado.append(['Snowball CountVectorizer Bigrama e stopwords com Naive Bayes', score])\n",
        "print('Snowball CountVectorizer Bigrama e stopwords com Naive Bayes:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Snowball CountVectorizer Bigrama e stopwords com Naive Bayes: 0.586125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5w6oY3mJiHg1",
        "outputId": "83393b64-c38d-4325-ae31-d33c030a1125"
      },
      "source": [
        "# Snowball CountVectorizer Trigrama e stopwords com Naive Bayes\n",
        "# treinamento do modelo Naive Bayes\n",
        "bayes = MultinomialNB()\n",
        "bayes.fit(snow_count3StopVect_train, df_train.sentimento)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "text_vect_test = snow_count3StopVect.transform(df_test.texto)\n",
        "y_prediction = bayes.predict(text_vect_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "score = f1_score(y_prediction, df_test.sentimento, average='weighted')\n",
        "resultado.append(['Snowball CountVectorizer Trigrama e stopwords com Naive Bayes', score])\n",
        "print('Snowball CountVectorizer Trigrama e stopwords com Naive Bayes:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Snowball CountVectorizer Trigrama e stopwords com Naive Bayes: 0.6650730607041289\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62nPAHlAiHg1"
      },
      "source": [
        "##### TfidfVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7OMg6qfiHg1",
        "outputId": "1863acbb-2e1f-4ecf-bc70-1124b5cedb52"
      },
      "source": [
        "# Snowball TfidfVectorizer Unigrama com Naive Bayes\n",
        "# treinamento do modelo Naive Bayes\n",
        "bayes = MultinomialNB()\n",
        "bayes.fit(snow_tfidf1Vect_train, df_train.sentimento)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "text_vect_test = snow_tfidf1Vect.transform(df_test.texto)\n",
        "y_prediction = bayes.predict(text_vect_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "score = f1_score(y_prediction, df_test.sentimento, average='weighted')\n",
        "resultado.append(['Snowball TfidfVectorizer Unigrama com Naive Bayes', score])\n",
        "print('Snowball TfidfVectorizer Unigrama com Naive Bayes:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Snowball TfidfVectorizer Unigrama com Naive Bayes: 0.6963192904656319\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJ6V7aLriHg1",
        "outputId": "3a4473f3-90bc-4e2f-b03c-b47e6fced13f"
      },
      "source": [
        "# Snowball TfidfVectorizer Bigrama com Naive Bayes\n",
        "# treinamento do modelo Naive Bayes\n",
        "bayes = MultinomialNB()\n",
        "bayes.fit(snow_tfidf2Vect_train, df_train.sentimento)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "text_vect_test = snow_tfidf2Vect.transform(df_test.texto)\n",
        "y_prediction = bayes.predict(text_vect_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "score = f1_score(y_prediction, df_test.sentimento, average='weighted')\n",
        "resultado.append(['Snowball TfidfVectorizer Bigrama com Naive Bayes', score])\n",
        "print('Snowball TfidfVectorizer Bigrama com Naive Bayes:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Snowball TfidfVectorizer Bigrama com Naive Bayes: 0.6404387155133423\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HU2l6Vn8iHg1",
        "outputId": "5eaa753d-8e58-4eef-fccf-6e1e380cec24"
      },
      "source": [
        "# Snowball TfidfVectorizer Trigrama com Naive Bayes\n",
        "# treinamento do modelo Naive Bayes\n",
        "bayes = MultinomialNB()\n",
        "bayes.fit(snow_tfidf3Vect_train, df_train.sentimento)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "text_vect_test = snow_tfidf3Vect.transform(df_test.texto)\n",
        "y_prediction = bayes.predict(text_vect_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "score = f1_score(y_prediction, df_test.sentimento, average='weighted')\n",
        "resultado.append(['Snowball TfidfVectorizer Trigrama com Naive Bayes', score])\n",
        "print('Snowball TfidfVectorizer Trigrama com Naive Bayes:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Snowball TfidfVectorizer Trigrama com Naive Bayes: 0.6164827586206897\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LO30_I5HiHg2"
      },
      "source": [
        "##### TfidfVectorizer + Stopwords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aL0oFBV9iHg2",
        "outputId": "d8c8afa6-253e-4ea9-ec7b-4d80fa4c366f"
      },
      "source": [
        "# Snowball TfidfVectorizer Unigrama e stopwords com Naive Bayes\n",
        "# treinamento do modelo Naive Bayes\n",
        "bayes = MultinomialNB()\n",
        "bayes.fit(snow_tfidf1StopVect_train, df_train.sentimento)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "text_vect_test = snow_tfidf1StopVect.transform(df_test.texto)\n",
        "y_prediction = bayes.predict(text_vect_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "score = f1_score(y_prediction, df_test.sentimento, average='weighted')\n",
        "resultado.append(['Snowball TfidfVectorizer Unigrama e stopwords com Naive Bayes', score])\n",
        "print('Snowball TfidfVectorizer Unigrama e stopwords com Naive Bayes:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Snowball TfidfVectorizer Unigrama e stopwords com Naive Bayes: 0.6913846153846154\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6Sx06ORiHg2",
        "outputId": "2172665f-3e5f-4dee-d6a0-b9371d33cc10"
      },
      "source": [
        "# Snowball TfidfVectorizer Bigrama e stopwords com Naive Bayes\n",
        "# treinamento do modelo Naive Bayes\n",
        "bayes = MultinomialNB()\n",
        "bayes.fit(snow_tfidf2StopVect_train, df_train.sentimento)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "text_vect_test = snow_tfidf2StopVect.transform(df_test.texto)\n",
        "y_prediction = bayes.predict(text_vect_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "score = f1_score(y_prediction, df_test.sentimento, average='weighted')\n",
        "resultado.append(['Snowball TfidfVectorizer Bigrama e stopwords com Naive Bayes', score])\n",
        "print('Snowball TfidfVectorizer Bigrama e stopwords com Naive Bayes:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Snowball TfidfVectorizer Bigrama e stopwords com Naive Bayes: 0.605359565807327\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0aSTcYTiHg2",
        "outputId": "d81c5baa-ea7c-471e-878f-a77a711fc1eb"
      },
      "source": [
        "# Snowball TfidfVectorizer Trigrama e stopwords com Naive Bayes\n",
        "# treinamento do modelo Naive Bayes\n",
        "bayes = MultinomialNB()\n",
        "bayes.fit(snow_tfidf3StopVect_train, df_train.sentimento)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "text_vect_test = snow_tfidf3StopVect.transform(df_test.texto)\n",
        "y_prediction = bayes.predict(text_vect_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "score = f1_score(y_prediction, df_test.sentimento, average='weighted')\n",
        "resultado.append(['Snowball TfidfVectorizer Trigrama e stopwords com Naive Bayes', score])\n",
        "print('Snowball TfidfVectorizer Trigrama e stopwords com Naive Bayes:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Snowball TfidfVectorizer Trigrama e stopwords com Naive Bayes: 0.666045564422663\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jq6bQ0evvCHT"
      },
      "source": [
        "#### Lemma\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvlzeQ9rvCHU"
      },
      "source": [
        "##### CountVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPRC8JxAvCHV",
        "outputId": "af767d04-89f2-4c7d-f077-c603c146dd63"
      },
      "source": [
        "# Lemma CountVectorizer Unigrama com Naive Bayes\n",
        "# treinamento do modelo Naive Bayes\n",
        "bayes = MultinomialNB()\n",
        "bayes.fit(lemma_count1Vect_train, df_train.sentimento)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "text_vect_test = lemma_count1Vect.transform(df_test.texto)\n",
        "y_prediction = bayes.predict(text_vect_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "score = f1_score(y_prediction, df_test.sentimento, average='weighted')\n",
        "resultado.append(['Lemma CountVectorizer Unigrama com Naive Bayes', score])\n",
        "print('Lemma CountVectorizer Unigrama com Naive Bayes:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Lemma CountVectorizer Unigrama com Naive Bayes: 0.73008100810081\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXGe6aNlvCHV",
        "outputId": "eb70a5f2-531a-4eaf-9f3b-5f0266b87462"
      },
      "source": [
        "# Lemma CountVectorizer Bigrama com Naive Bayes\n",
        "# treinamento do modelo Naive Bayes\n",
        "bayes = MultinomialNB()\n",
        "bayes.fit(lemma_count2Vect_train, df_train.sentimento)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "text_vect_test = lemma_count2Vect.transform(df_test.texto)\n",
        "y_prediction = bayes.predict(text_vect_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "score = f1_score(y_prediction, df_test.sentimento, average='weighted')\n",
        "resultado.append(['Lemma CountVectorizer Bigrama com Naive Bayes', score])\n",
        "print('Lemma CountVectorizer Bigrama com Naive Bayes:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Lemma CountVectorizer Bigrama com Naive Bayes: 0.6765456209948124\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQ9LsnwdvCHW",
        "outputId": "c9c7fb5f-7c6f-4cfa-d6ae-6072afb60940"
      },
      "source": [
        "# Lemma CountVectorizer Trigrama com Naive Bayes\n",
        "# treinamento do modelo Naive Bayes\n",
        "bayes = MultinomialNB()\n",
        "bayes.fit(lemma_count3Vect_train, df_train.sentimento)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "text_vect_test = lemma_count3Vect.transform(df_test.texto)\n",
        "y_prediction = bayes.predict(text_vect_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "score = f1_score(y_prediction, df_test.sentimento, average='weighted')\n",
        "resultado.append(['Lemma CountVectorizer Trigrama com Naive Bayes', score])\n",
        "print('Lemma CountVectorizer Trigrama com Naive Bayes:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Lemma CountVectorizer Trigrama com Naive Bayes: 0.6257240652975249\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8Q9yMy2vCHW"
      },
      "source": [
        "##### CountVectorizer + Stopwords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9F3eJIZjvCHW",
        "outputId": "2981fe90-0e6e-4b77-e7c1-d48fea0328f4"
      },
      "source": [
        "# Lemma CountVectorizer Unigrama e stopwords com Naive Bayes\n",
        "# treinamento do modelo Naive Bayes\n",
        "bayes = MultinomialNB()\n",
        "bayes.fit(lemma_count1StopVect_train, df_train.sentimento)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "text_vect_test = lemma_count1StopVect.transform(df_test.texto)\n",
        "y_prediction = bayes.predict(text_vect_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "score = f1_score(y_prediction, df_test.sentimento, average='weighted')\n",
        "resultado.append(['Lemma CountVectorizer Unigrama e stopwords com Naive Bayes', score])\n",
        "print('Lemma CountVectorizer Unigrama e stopwords com Naive Bayes:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Lemma CountVectorizer Unigrama e stopwords com Naive Bayes: 0.7217784050811573\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZOrQQ2tvCHW",
        "outputId": "cf5bda8a-e8e4-4377-b792-4a9d0bf58d3a"
      },
      "source": [
        "# Lemma CountVectorizer Bigrama e stopwords com Naive Bayes\n",
        "# treinamento do modelo Naive Bayes\n",
        "bayes = MultinomialNB()\n",
        "bayes.fit(lemma_count2StopVect_train, df_train.sentimento)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "text_vect_test = lemma_count2StopVect.transform(df_test.texto)\n",
        "y_prediction = bayes.predict(text_vect_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "score = f1_score(y_prediction, df_test.sentimento, average='weighted')\n",
        "resultado.append(['Lemma CountVectorizer Bigrama e stopwords com Naive Bayes', score])\n",
        "print('Lemma CountVectorizer Bigrama e stopwords com Naive Bayes:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Lemma CountVectorizer Bigrama e stopwords com Naive Bayes: 0.63\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yrB39bkcvCHX",
        "outputId": "0ad51c08-69f5-4204-9683-3b47aaaed9b0"
      },
      "source": [
        "# Lemma CountVectorizer Trigrama e stopwords com Naive Bayes\n",
        "# treinamento do modelo Naive Bayes\n",
        "bayes = MultinomialNB()\n",
        "bayes.fit(lemma_count3StopVect_train, df_train.sentimento)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "text_vect_test = lemma_count3StopVect.transform(df_test.texto)\n",
        "y_prediction = bayes.predict(text_vect_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "score = f1_score(y_prediction, df_test.sentimento, average='weighted')\n",
        "resultado.append(['Lemma CountVectorizer Trigrama e stopwords com Naive Bayes', score])\n",
        "print('Lemma CountVectorizer Trigrama e stopwords com Naive Bayes:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Lemma CountVectorizer Trigrama e stopwords com Naive Bayes: 0.6577649835730917\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OcLhCV4vCHX"
      },
      "source": [
        "##### TfidfVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXQ6wQm3vCHX",
        "outputId": "afdbefef-1674-4103-fbe0-da9dd3c73d8a"
      },
      "source": [
        "# Lemma TfidfVectorizer Unigrama com Naive Bayes\n",
        "# treinamento do modelo Naive Bayes\n",
        "bayes = MultinomialNB()\n",
        "bayes.fit(lemma_tfidf1Vect_train, df_train.sentimento)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "text_vect_test = lemma_tfidf1Vect.transform(df_test.texto)\n",
        "y_prediction = bayes.predict(text_vect_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "score = f1_score(y_prediction, df_test.sentimento, average='weighted')\n",
        "resultado.append(['Lemma TfidfVectorizer Unigrama com Naive Bayes', score])\n",
        "print('Lemma TfidfVectorizer Unigrama com Naive Bayes:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Lemma TfidfVectorizer Unigrama com Naive Bayes: 0.7504672250826097\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzFwiOz9vCHX",
        "outputId": "47c85855-3f47-491a-a52a-42f02f1516bb"
      },
      "source": [
        "# Lemma TfidfVectorizer Bigrama com Naive Bayes\n",
        "# treinamento do modelo Naive Bayes\n",
        "bayes = MultinomialNB()\n",
        "bayes.fit(lemma_tfidf2Vect_train, df_train.sentimento)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "text_vect_test = lemma_tfidf2Vect.transform(df_test.texto)\n",
        "y_prediction = bayes.predict(text_vect_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "score = f1_score(y_prediction, df_test.sentimento, average='weighted')\n",
        "resultado.append(['Lemma TfidfVectorizer Bigrama com Naive Bayes', score])\n",
        "print('Lemma TfidfVectorizer Bigrama com Naive Bayes:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Lemma TfidfVectorizer Bigrama com Naive Bayes: 0.7332873376623377\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xHL43tkvCHY",
        "outputId": "5d5bbbd3-d506-473d-a7e6-a3fc8c594c5b"
      },
      "source": [
        "# Lemma TfidfVectorizer Trigrama com Naive Bayes\n",
        "# treinamento do modelo Naive Bayes\n",
        "bayes = MultinomialNB()\n",
        "bayes.fit(lemma_tfidf3Vect_train, df_train.sentimento)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "text_vect_test = lemma_tfidf3Vect.transform(df_test.texto)\n",
        "y_prediction = bayes.predict(text_vect_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "score = f1_score(y_prediction, df_test.sentimento, average='weighted')\n",
        "resultado.append(['Lemma TfidfVectorizer Trigrama com Naive Bayes', score])\n",
        "print('Lemma TfidfVectorizer Trigrama com Naive Bayes:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Lemma TfidfVectorizer Trigrama com Naive Bayes: 0.6198511487433934\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPRfdazTvCHY"
      },
      "source": [
        "##### TfidfVectorizer + Stopwords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQ6eT7JBvCHY",
        "outputId": "4cd51579-f63f-4005-d9ec-3f452f20c805"
      },
      "source": [
        "# Lemma TfidfVectorizer Unigrama e stopwords com Naive Bayes\n",
        "# treinamento do modelo Naive Bayes\n",
        "bayes = MultinomialNB()\n",
        "bayes.fit(lemma_tfidf1StopVect_train, df_train.sentimento)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "text_vect_test = lemma_tfidf1StopVect.transform(df_test.texto)\n",
        "y_prediction = bayes.predict(text_vect_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "score = f1_score(y_prediction, df_test.sentimento, average='weighted')\n",
        "resultado.append(['Lemma TfidfVectorizer Unigrama e stopwords com Naive Bayes', score])\n",
        "print('Lemma TfidfVectorizer Unigrama e stopwords com Naive Bayes:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Lemma TfidfVectorizer Unigrama e stopwords com Naive Bayes: 0.7329466162253047\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9C9GMBhvCHY",
        "outputId": "9a2de6fe-78ba-4547-a785-c565cb49c0fc"
      },
      "source": [
        "# Lemma TfidfVectorizer Bigrama e stopwords com Naive Bayes\n",
        "# treinamento do modelo Naive Bayes\n",
        "bayes = MultinomialNB()\n",
        "bayes.fit(lemma_tfidf2StopVect_train, df_train.sentimento)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "text_vect_test = lemma_tfidf2StopVect.transform(df_test.texto)\n",
        "y_prediction = bayes.predict(text_vect_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "score = f1_score(y_prediction, df_test.sentimento, average='weighted')\n",
        "resultado.append(['Lemma TfidfVectorizer Bigrama e stopwords com Naive Bayes', score])\n",
        "print('Lemma TfidfVectorizer Bigrama e stopwords com Naive Bayes:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Lemma TfidfVectorizer Bigrama e stopwords com Naive Bayes: 0.6275805626598465\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xE7tI1-fvCHY",
        "outputId": "ba734f4c-c204-4d4f-ca01-a19786ef9bdd"
      },
      "source": [
        "# Lemma TfidfVectorizer Trigrama e stopwords com Naive Bayes\n",
        "# treinamento do modelo Naive Bayes\n",
        "bayes = MultinomialNB()\n",
        "bayes.fit(lemma_tfidf3StopVect_train, df_train.sentimento)\n",
        "\n",
        "# escoragem da classificação na amostra de teste\n",
        "text_vect_test = lemma_tfidf3StopVect.transform(df_test.texto)\n",
        "y_prediction = bayes.predict(text_vect_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "score = f1_score(y_prediction, df_test.sentimento, average='weighted')\n",
        "resultado.append(['Lemma TfidfVectorizer Trigrama e stopwords com Naive Bayes', score])\n",
        "print('Lemma TfidfVectorizer Trigrama e stopwords com Naive Bayes:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Lemma TfidfVectorizer Trigrama e stopwords com Naive Bayes: 0.6575895263765884\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAc0jzmiAVso"
      },
      "source": [
        "## Resultados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "10ZwAMsgAVsp",
        "outputId": "5d4d7479-676f-40fd-f370-63f88d67cfec"
      },
      "source": [
        "# Resumo de resultados\n",
        "df_res = pd.DataFrame(np.unique(np.array(resultado), axis=0), columns=['Técnica', 'F1 Score'])\n",
        "df_res.sort_values(by='F1 Score', ascending=False)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Técnica</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>Texto CountVectorizer Bigrama com Naive Bayes</td>\n",
              "      <td>0.8001600640256101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>Texto TfidfVectorizer Unigrama com Naive Bayes</td>\n",
              "      <td>0.799395220164451</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>Texto CountVectorizer Unigrama com Naive Bayes</td>\n",
              "      <td>0.7951076492210748</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>Texto TfidfVectorizer Bigrama com Naive Bayes</td>\n",
              "      <td>0.7910161186331399</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>Texto CountVectorizer Unigrama e stopwords com...</td>\n",
              "      <td>0.7900630063006301</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Lemma CountVectorizer Bigrama com arvore de de...</td>\n",
              "      <td>0.595648452929559</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>Snowball CountVectorizer Bigrama e stopwords c...</td>\n",
              "      <td>0.586125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>Texto TfidfVectorizer Trigrama com arvore de d...</td>\n",
              "      <td>0.5798850574712644</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>Snowball CountVectorizer Trigrama com Naive Bayes</td>\n",
              "      <td>0.5701291162045841</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>Snowball TfidfVectorizer Bigrama com arvore de...</td>\n",
              "      <td>0.5285712443584785</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>96 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              Técnica            F1 Score\n",
              "72      Texto CountVectorizer Bigrama com Naive Bayes  0.8001600640256101\n",
              "92     Texto TfidfVectorizer Unigrama com Naive Bayes   0.799395220164451\n",
              "80     Texto CountVectorizer Unigrama com Naive Bayes  0.7951076492210748\n",
              "84      Texto TfidfVectorizer Bigrama com Naive Bayes  0.7910161186331399\n",
              "82  Texto CountVectorizer Unigrama e stopwords com...  0.7900630063006301\n",
              "..                                                ...                 ...\n",
              "1   Lemma CountVectorizer Bigrama com arvore de de...   0.595648452929559\n",
              "50  Snowball CountVectorizer Bigrama e stopwords c...            0.586125\n",
              "89  Texto TfidfVectorizer Trigrama com arvore de d...  0.5798850574712644\n",
              "52  Snowball CountVectorizer Trigrama com Naive Bayes  0.5701291162045841\n",
              "61  Snowball TfidfVectorizer Bigrama com arvore de...  0.5285712443584785\n",
              "\n",
              "[96 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SK43gjEcw12W",
        "outputId": "d97c8902-3ee7-4422-c326-66bb8e8cbc06"
      },
      "source": [
        "print(df_res.iloc[10, 0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Lemma CountVectorizer Unigrama e stopwords com Naive Bayes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68SiMjcWqD_m"
      },
      "source": [
        "## Validação do professor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T24EasckqG2I"
      },
      "source": [
        "Consolidar apenas os scripts do seu **modelo campeão**, desde o carregamento do dataframe, separação das amostras, tratamentos (funções, limpeza, etc.), criação dos objetos de vetorização e modelo treinado e outras implementações utilizadas no processo de desenvolvimento do modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VF8HQtd2gjSE",
        "outputId": "6b009b27-3aaa-4428-b266-fddf073577d1"
      },
      "source": [
        "# Import e downlaod de bibliotecas utilizadas a seguir\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import nltk\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "df_full = pd.read_csv('bases/reviews-pt-br.csv', encoding='utf-8')\n",
        "\n",
        "df_train, df_test = train_test_split(df_full.copy(), test_size = 0.2, random_state = 42)\n",
        "\n",
        "# print('Treino: df_train', df_train.shape)\n",
        "# print('Treino: df_test', df_test.shape)\n",
        "\n",
        "# CountVectorizer com bigrama usando o texto original\n",
        "text_count2Vect = CountVectorizer(ngram_range=(2,2))\n",
        "text_count2Vect.fit(df_train.texto)\n",
        "text_count2Vect_train = text_count2Vect.transform(df_train.texto)\n",
        "\n",
        "# Texto CountVectorizer Bigrama com Naive Bayes\n",
        "# treinamento do modelo Naive Bayes\n",
        "bayes = MultinomialNB()\n",
        "bayes.fit(text_count2Vect_train, df_train.sentimento)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAWTX7gXC759"
      },
      "source": [
        "dfTeste = df_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6bv4mm7rrUH"
      },
      "source": [
        "Aqui implemente a parte do **script de teste** do seu modelo e imprima a métrica F1 Score no final do script.\n",
        "\n",
        "Obs.: Pense que o professor irá subistituir seu dataframe de teste ( **dfTeste** ) por outro e testar a performance do seu modelo com dados que não foram utilizados no desenvolvimento."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6ezqmGVo3MA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d2432586-e2ee-41e7-f2d2-8fc1389f9ba2"
      },
      "source": [
        "'''\n",
        "# PARTE DO PROFESSOR  \n",
        "import pandas as pd  \n",
        "arquivo = 'url do professor'  \n",
        "dfValidacao = pd.read_csv(arquivo, encoding='utf-8')  \n",
        "dfTeste = dfValidacao  \n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\n# PARTE DO PROFESSOR  \\nimport pandas as pd  \\narquivo = 'url do professor'  \\ndfValidacao = pd.read_csv(arquivo, encoding='utf-8')  \\ndfTeste = dfValidacao  \\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuJtvcfXo3J4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b70835f1-f7fa-47e4-b839-715f47b19524"
      },
      "source": [
        "# escoragem da classificação na amostra de teste\n",
        "text_vect_test = text_count2Vect.transform(dfTeste.texto)\n",
        "y_prediction = bayes.predict(text_vect_test)\n",
        "\n",
        "# mensuração do resultado pela acurácia\n",
        "score = f1_score(y_prediction, dfTeste.sentimento, average='weighted')\n",
        "# resultado.append(['Texto CountVectorizer Bigrama com Naive Bayes', score])\n",
        "print('Texto CountVectorizer Bigrama com Naive Bayes:', score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Texto CountVectorizer Bigrama com Naive Bayes: 0.8843036455724294\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}